{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Verify Developer Documentation","text":"<p>AI Verify is built with extensibility and open source collaboration in mind. Adopting a modular software design approach, it is powered by a plugin system, where features ranging from report templates to testing algorithms can be customised and enhanced through an AI Verify plugin. In the spirit of open source, AI Verify welcomes developers and interested parties to collaborate together and get started here.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We encourage everyone to contribute to AI Verify and that\u2019s why we have put up this developer\u2019s guide. If you still have questions after reading the material, please take a look at the Contributing Guidelines.</p> <p>For first time contributors, we hope you find the following guide from Open Source Guides useful:</p> <ul> <li>How to Contribute to Open Source</li> </ul>"},{"location":"#bugs","title":"Bugs","text":"<p>If you come across a bug with our API or want to report incorrect documentation, please open an issue on our issue tracker.</p>"},{"location":"getting_started/install_aiverify_dev_tools/","title":"Installing AI Verify Developer Tools","text":""},{"location":"getting_started/install_aiverify_dev_tools/#before-you-begin","title":"Before You Begin","text":"<p>This page prepares your environment for development on AI Verify. By the end of this guided example, you should end up with the following folder structure.</p> <p><pre><code>&lt;working directory&gt;/\n\u251c\u2500\u2500 aiverify/\n    \u251c\u2500\u2500 ai-verify-shared-library/\n    \u251c\u2500\u2500 test-engine-core/\n    \u2514\u2500\u2500 test-engine-core-modules/\n\u251c\u2500\u2500 aiverify-developer-tools/\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 ai-verify-algorithm-template/\n    \u251c\u2500\u2500 ai-verify-plugin/\n    \u2514\u2500\u2500 template_plugin/\n\u2514\u2500\u2500 my_virtual_environment/\n</code></pre> The Developer Tools require specific modules from the main AI Verify repository. If you have not installed AI Verify, use sparse-checkout on the AI Verify repository to selectively checkout files that are relevant to the Developer Tools.</p> <ol> <li>Clone the required modules and selectively checkout dependencies needed for Developer Tools <pre><code># Execute in the working directory\ngit clone git@github.com:IMDA-BTG/aiverify.git # requires Github public SSH key\ncd aiverify\ngit sparse-checkout init --cone\ngit sparse-checkout set ai-verify-shared-library test-engine-core-modules test-engine-core\n\nls # You should be able to see the three folders\n</code></pre></li> </ol> <p>After the sparse checkout, you should end up with these three folders in your aiverify project directory. Please take note of the test-engine-core-modules path, as you will need it later while testing the algorithm component. </p> <p></p>"},{"location":"getting_started/install_aiverify_dev_tools/#installing-dependencies","title":"Installing Dependencies","text":"<p>Install the following dependencies if they are not already available.</p> <ol> <li> <p>Install jq and zip <pre><code>sudo apt-get install -y jq zip\n</code></pre></p> </li> <li> <p>Install Python and its virtual environment packages <pre><code>sudo apt-get install -y python3.10 python3-pip python3.10-venv\n</code></pre></p> </li> <li> <p>Install NodeJS <pre><code>curl -sL https://deb.nodesource.com/setup_18.x | sudo -E bash -\nsudo apt-get install -y nodejs\n</code></pre></p> </li> </ol>"},{"location":"getting_started/install_aiverify_dev_tools/#preparing-a-virtual-environment","title":"Preparing a Virtual Environment","text":"<p>We recommend setting up a virtual environment for your plugin project to ensure that these libraries will not mess up your main development environment.</p> <ol> <li> <p>Create a virtual environment <pre><code># Execute in the working directory\npython3 -m venv my_virtual_environment\n</code></pre></p> </li> <li> <p>Activate your newly created virtual environment <pre><code>source my_virtual_environment/bin/activate\n</code></pre></p> </li> <li> <p>Check that you're working from the virtual environment <pre><code>which python # you should see something like &lt;working directory&gt;/my_virtual_environment/bin/python\n</code></pre></p> </li> <li> <p>Install plugin dependencies in your virtual environment <pre><code>pip install --upgrade pip\npip install cookiecutter\n</code></pre></p> </li> <li> <p>Install AI Verify Test Engine Core. <pre><code># Execute these in the aiverify directory\ncd test-engine-core\npip install dist/test_engine_core-0.9.0.tar.gz\n\n# Head back to the aiverify directory\ncd ..\n</code></pre></p> <p>Note</p> <p>AI Verify Test Engine currently runs Pandas V1.5.3. We do not support Pandas 2.x.x.</p> </li> <li> <p>Install necessary requirements from <code>test-engine-core-modules</code>. <pre><code># Execute these in the aiverify directory\ncd test-engine-core-modules\npip install -r requirements.txt\n\n# Head back to the aiverify directory\ncd ..\n</code></pre></p> </li> <li> <p>Install dependencies and build AI Verify Frontend Shared Library <pre><code># Execute these in the aiverify directory\ncd ai-verify-shared-library\nnpm install\nnpm run build\n\n# Head back to the aiverify directory\ncd ..\n</code></pre></p> </li> </ol>"},{"location":"getting_started/install_aiverify_dev_tools/#installing-ai-verify-developer-tools_1","title":"Installing AI Verify Developer Tools","text":"<p>Install AI Verify Developer Tools in your environment.</p> <ol> <li> <p>Clone our developer's repository. We recommend cloning this in the same directory you cloned aiverify. <pre><code># Execute in the working directory\ngit clone https://github.com/IMDA-BTG/aiverify-developer-tools.git\n</code></pre></p> </li> <li> <p>Install AI Verify Frontend Plugin Tool <pre><code>cd aiverify-developer-tools/ai-verify-plugin\nnpm install\nnpm install ../../aiverify/ai-verify-shared-library\nsudo npm install -g # You may need sudo for this command\n</code></pre></p> </li> </ol> <p>If the installation is successful, you should see a similar output as shown below.</p>"},{"location":"getting_started/install_aiverify_dev_tools/#ai-verify-plugin","title":"ai-verify-plugin","text":"<pre><code>ai-verify-plugin --help\n</code></pre>"},{"location":"getting_started/install_aiverify_dev_tools/#cookiecutter","title":"cookiecutter","text":"<pre><code>cookiecutter -h\n</code></pre> <p>Congratulations! You are ready to create your first plugin.</p>"},{"location":"getting_started/start_here/","title":"Getting Started","text":"<p>The developer guide is designed to be beginner-friendly for developers, but assumes some familiarity and proficiency in Python, Javascript, and MDX.</p>"},{"location":"getting_started/start_here/#learning-objectives","title":"Learning Objectives","text":"<p>You will learn to:</p> <ol> <li>Install AI Verify Developer Tools</li> <li>Introduction to AI Verify Plugins</li> <li>Create an algorithm component that will return the values of a selected feature of your test dataset</li> <li>Create an widget component that will print out the output from the algorithm component</li> <li>Package algorithm and widget components into a single deployable plugin</li> <li>Debugging workflow other avenues to seek help</li> </ol>"},{"location":"getting_started/start_here/#system-requirements","title":"System Requirements","text":"<p>To start developing on AI Verify, you will need to install AI Verify Developer Tools. These are the minimum requirements to run AI Verify on a local computer:</p> <ul> <li>Ubuntu 22.04 (64-bit)</li> <li>At least 3GB disk space to download and install AI Verify and Developer Tools</li> <li>At least 4GB memory</li> </ul> <p>Warning</p> <p>We do not officially provide support for Windows. For Windows developers, AI Verify requires minimally Windows 10 with WSL2. Please note that we have not conducted tests on Windows 10. Please follow instructions to set up WSL2 here if you still wish to proceed.</p>"},{"location":"getting_started/start_here/#installing-ai-verify","title":"Installing AI Verify","text":"<p>Installation of AI Verify is optional during the development phase. For those interested, we recommend using the source code installation method for easier debugging. This can be found in the User Guide.</p>"},{"location":"getting_started/start_here/#installing-ai-verify-developer-tools","title":"Installing AI Verify Developer Tools","text":"<p>Upon installing AI Verify, please proceed with the installation of the Developer Tools.</p>"},{"location":"getting_started/start_here/#building-your-first-ai-verify-plugin","title":"Building your first AI Verify plugin","text":"<p>In this tutorial, you will learn about the fundamental concepts to build a plugin. This guide will walk you through building your first AI Verify plugin using both Javascript and Python, and by the end you will have a working plugin that can be loaded on AI Verify to run an algorithm and generate a simple report.</p>"},{"location":"guided_example/deploy_your_plugin/","title":"Deploy Your Plugin","text":"<p>Now that you have created your plugin component(s), it is time to package it into a single plugin for deployment.</p> <p>If you are following the guided example, you should have the following components completed and packaged in its own respective folders:</p> <ol> <li>your-first-algorithm-component component</li> <li>your-first-widget component</li> </ol> <p>At this point, you may decide if you wish to deploy the components as two separate plugins (i.e. algorithm plugin and widget plugin), or combine and package it as a single plugin. Each method comes with its own rationale and benefit.</p> Deployment Style Description Rationale Combine Combine components into a single plugin zip Combine components when they are tightly coupled, eg. input block component needed for the algorithm component to run properly, widget component needed to display algorithm results etc Separate Separate the components into its own respective plugin zips This is a more modular design approach. Some components do not have additional dependencies, or are add-ons to existing plugins. eg. Additional widget plugins for different ways to display algorithm results."},{"location":"guided_example/deploy_your_plugin/#combine-the-plugin-components","title":"Combine the plugin components","text":"<p>The template_plugin directory should mimic the same plugin structure. The algorithms directory should contain algorithms, with each one in its own respective folder. The widget components will be stored in the widgets directory.</p> <p></p> <p>In this guided example, the algorithms directory will have the folder your_first_algorithm_component. The widgets directory will contain mywidget.meta.json, mywidget.mdx, and your_first_algorithm_component.sample.json.</p> <p>It should look something like this:</p> <p></p>"},{"location":"guided_example/deploy_your_plugin/#edit-plugin-details-optional","title":"Edit Plugin Details (Optional)","text":"<p>You may wish to edit plugin.meta.json to change the plugin details.</p> plugin.meta.json<pre><code>{\n\"gid\": \"your_first_plugin\",\n\"version\": \"0.1.0\",\n\"name\": \"Your First Plugin\",\n\"author\": \"Example Author\",\n\"description\": \"This is your first plugin\"\n}\n</code></pre>"},{"location":"guided_example/deploy_your_plugin/#deploy-your-plugin_1","title":"Deploy your Plugin","text":"<p>We have provided a script that helps package and deploy your plugin. If you have not created a widget component at this point, this will package the algorithm as a standalone plugin. To run the script, navigate to the directory with the script <code>deploy_plugin.sh</code>. This is located at the root of template_plugin folder. At the directory, enter:</p> <pre><code># Execute this script in the template_plugin directory\n./deploy_plugin.sh\n</code></pre> <p>Note</p> <p>A new folder <code>dist</code> will be created. This folder is where the packaged <code>.zip</code> file will be created and placed.</p> <p>If you did not edit the gid, verify that the zip file <code>your_first_plugin-0.1.0.zip</code> exists in your <code>dist</code> directory:</p> <pre><code>ls dist | grep your_first_plugin\n</code></pre> <p>The resulting plugin is packaged as a <code>zip</code> file, which can be used to share with other developers who are interested in using your plugin. Users and developers can then upload the zip file onto AI Verify through the plugin manager and use it in the report.</p> <p></p>"},{"location":"guided_example/deploy_your_plugin/#uploading-the-plugin","title":"Uploading the plugin","text":"<p>To upload the plugin, start the frontend portal of AI Verify. You will need to install AI Verify if you have not done so. The instructions to install and run AI Verify from source code can be found in the User Guide.</p> <ol> <li> <p>Once the portal is started up, visit the portal at http://localhost:3000/home. In the homepage, click on \"Plugins\" to visit the Plugin Manager page:    </p> </li> <li> <p>In the Plugin Manager page, click on \"INSTALL PLUGIN\" at the top right and select <code>your_first_plugin-0.1.0.zip</code>, then click on \"INSTALL\" :    </p> </li> <li> <p>The following prompt should appear to inform you that the plugin has been installed successfully: </p> <p></p> </li> <li> <p>You should see your plugin in the list of installed plugins:    </p> </li> </ol>"},{"location":"guided_example/deploy_your_plugin/#generating-the-report","title":"Generating the Report","text":"<ol> <li>It is time to run the plugin. In the homepage, click on \"Create New Project\":    </li> <li>Fill in the project details and click \"Next\" on the top right:     </li> <li>On the Design Report page, drag your widget from the left panel to the canvas:        You can resize the the widget and click on the alignment buttons to refresh its size. When you're ready, click \"Next\" on the top right.</li> <li> <p>On the Select the Datasets and AI Model to be tested page, select and upload the dataset, ground truth dataset and model. You can use the dataset provided in the template or download from here. Refer to the following table for reference.</p> Data, Model, and Test Arguments Selected Dataset / Model / Test Arguments Testing Dataset <code>pickle_pandas_mock_binary_classification_credit_risk_testing.sav</code> Ground Truth Dataset <code>pickle_pandas_mock_binary_classification_credit_risk_testing.sav</code>, Ground Truth: <code>default</code> AI Model <code>binary_classification_mock_credit_risk_sklearn.linear_model._logistic.LogisticRegression.sav</code> Test Arguments <code>gender</code> </li> <li> <p>For the model, choose <code>Upload AI Model</code> and click \"Next\".    </p> </li> <li>We will be uploading the <code>binary_classification_mock_credit_risk_sklearn.linear_model._logistic.LogisticRegression.sav</code> model.     </li> <li>Type <code>gender</code> into the plugin arguments. The end result should look like this.     </li> <li>When you are ready, click on \"Next\" on the top right. Click on \"PROCEED\" when prompted:     </li> <li>You should see the logs of what is happening in the backend and when your report has been generated, you should see the \"Test Completed\" prompt in the top right. Click on \"VIEW REPORT\" to see your report:     </li> <li>Your report will be displayed as a PDF file.         Congratulations! You have generated your first report. </li> </ol>"},{"location":"guided_example/introduction_to_plugins/","title":"Introduction to Plugins","text":""},{"location":"guided_example/introduction_to_plugins/#ai-verify-plugins","title":"AI Verify Plugins","text":"<p>AI Verify Plugins are the modular building blocks that power AI Verify. It is extensible and dynamically loaded onto AI Verify. Here are some examples of what you can achieve with plugins.</p> <ul> <li>Add a custom widget to display result graphs on the report</li> <li>Create new testing algorithms to enhance testing capabilities in AI Verify</li> </ul>"},{"location":"guided_example/introduction_to_plugins/#anatomy-of-a-plugin","title":"Anatomy of a Plugin","text":"<p>The diagram shows an example of the plugin structure.</p> <p></p> <p>Each plugin comes packaged in a zip file with the following file structure. It can contain one or more components.</p>"},{"location":"guided_example/introduction_to_plugins/#plugin-components","title":"Plugin Components","text":"<p>A plugin can extend the functionality of AI Verify in four ways:</p> Type of Component Description Algorithm Extend AI Verify with new testing algorithm to run technical test on AI model Widget Extend AI Verify with new visualisation for customised report Input Block Extend AI Verify with new requested parameters from the user Template Extend AI Verify with unique and reusable report templates"},{"location":"guided_example/introduction_to_plugins/#terminology","title":"Terminology","text":"Term Definition plugin AI Verify plugin that can be installed using the AI Verify portal. component Each AI Verify plugin consists of one or more components and can be used to extend the functionality of the system. These are listed in details below. gid Global Identifier. All plugins requires a unique global identifier that is used to identify the plugin. See Widget for more details cid Component ID. Unique ID that identifies the component within the plugin. See Widget for more details"},{"location":"guided_example/introduction_to_plugins/#algorithm","title":"Algorithm","text":"<p>Each algorithm has its own subfolder under the algorithms folder named with the algorithm id. For example, algorithmA should have a sub-folder called \"algorithmA\" under the algorithms folder.</p>"},{"location":"guided_example/introduction_to_plugins/#widget-input-block-and-template","title":"Widget, Input Block and Template","text":"<p>Each instance of the components should be saved under the component folder; and the filenames of the component should correspond to the component cid. For example, widgetA should have the following files under the widgets folder.</p> <ul> <li>widgetA.meta.json</li> <li>widgetA.mdx</li> </ul>"},{"location":"guided_example/introduction_to_plugins/#template-plugin-structure","title":"Template Plugin Structure","text":"<p>In the aiverify-developer-tools repository, the template_plugin folder follows the plugin structure as mentioned above. The deploy_plugin.sh helper script helps to check and package the components into a single zip file for deployment.</p> <p>Info</p> <p>Use the template_plugin folder to store the components before deploying it with deploy_plugin.sh.</p>"},{"location":"guided_example/your_first_algorithm/","title":"Creating your First Algorithm Component","text":"<p>In this guided example, you will be building a plugin that takes in a feature value from the user and prints out that value in a generated report. This plugin requires two type of components: algorithm and widget (See this page for more details on Plugins). </p> <p>There are three objectives in this algorithm component example:</p> <ol> <li>Modify the input schema for the algorithm to receive user input</li> <li>Modify the output schema and and write code to return the expected output</li> <li>Modify the testing codes</li> </ol>"},{"location":"guided_example/your_first_algorithm/#generating-the-algorithm-component-project","title":"Generating the algorithm component project","text":"<p>First, we will have to create a new algorithm component project. If you haven't setup your environment, follow the instructions on this page before continuing. </p> <p>Info</p> <p>For this guided example, we will be using the template_plugin folder to store the algorithm and widget components, before using deploy_plugin.sh helper script to package and deploy the final plugin zip.</p> <p>Algorithms are stored in the template_plugin/algorithms folder. From your terminal, use <code>cookiecutter</code> to generate an algorithm component template for your new algorithm.</p> <pre><code># From the aiverify-developer-tools project directory\ncd template_plugin/algorithms\n\n# use cookiecutter with the algorithm template\ncookiecutter ../../ai-verify-algorithm-template\n</code></pre> <p>Answer the following questions:</p> Required Input Action author [example_author] We will use the default. Press Enter. plugin_name [example plugin] Type your-first-algorithm-component. Press Enter. Choose from 1 [1] We will use the default. Press Enter. plugin_version [0.1.0] We will use the default. Press Enter. plugin_description [My example plugin] Type Your first algorithm component. Press Enter. Select license [1] We will use the default. Press Enter. Select algo_model_support [1] We will use the default. Press Enter. Select require_ground_truth [1] We will use the default. Press Enter. <p>Note</p> <p>The plugin name <code>your-first-algorithm-component</code> will automatically be converted to <code>your_first_algorithm_component</code>. The cookiecutter generator will automatically convert the name to create the project slug. Refer to the guide on Package and Module Names.</p> <p>Verify that the directory <code>your_first_algorithm_component</code> exists in your current directory:</p> <pre><code>ls | grep your_first_algorithm_component\n</code></pre> <p></p> <p>If you do not see the project name, something in the setup is incomplete. Please re-create the project directory through the steps above again.</p> <p>Yay! You have generated an algorithm component project to create your first algorithm (See more details at Understanding your algorithm project)</p>"},{"location":"guided_example/your_first_algorithm/#modifying-input-schema","title":"Modifying input schema","text":"<p>Modify <code>input.schema.json</code> to request an input called <code>feature_name</code> from the user when the user uses this algorithm. Notice the highlighted lines that requires a <code>feature_name</code> field, and the properties of the <code>feature_name</code> is also defined.</p> input.schema.json<pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_name\"\n],\n\"properties\": {\n\"feature_name\": {\n\"title\": \"Feature Name\",\n\"description\": \"Indicate the feature name to be extracted from the data file\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#modifying-algorithm","title":"Modifying algorithm","text":"<p>Modify <code>your_first_algorithm_component.py</code> to receive and return the data of the requested <code>feature_name</code>. </p> <p>Tip</p> <p>All codes generated using the <code>cookiecutter</code> template has been annotated with <code>TODO:</code> for users to quickly navigate to areas that require code modification.</p> <p>First, update the description of this algorithm in the code.</p> your_first_algorithm_component.py<pre><code>class Plugin(IAlgorithm):\n\"\"\"\n    # TODO: Update the plugin description below\n    The Plugin(your-first-algorithm-component) class specifies methods in generating results for algorithm\n    \"\"\"\n# Some information on component\n_name: str = \"your-first-algorithm-component\"\n_description: str = \"This algorithm returns the value of the feature name selected by the user.\"\n_version: str = \"0.1.0\"\n_metadata: PluginMetadata = PluginMetadata(_name, _description, _version)\n_plugin_type: PluginType = PluginType.ALGORITHM\n_requires_ground_truth: bool = False\n</code></pre> <p>Next, update the <code>generate</code> method to retrieve the return the values of the selected <code>feature_name</code> in a given sample data file.</p> your_first_algorithm_component.py<pre><code>    def generate(self) -&gt; None:\n\"\"\"\n        A method to generate the algorithm results with the provided data, model, ground truth information.\n        \"\"\"\n# Retrieve data information\nself._data = self._data_instance.get_data()\n# TODO: Insert algorithm logic for this plug-in.\n# Retrieve the input arguments\nmy_user_defined_feature_name = self._input_arguments['feature_name']\n# Get the values of the feature name and convert to a list.\nself._results = {\n\"my_expected_results\": list(self._data[my_user_defined_feature_name].values)\n}\n# Update progress (For 100% completion)\nself._progress_inst.update(1)\n</code></pre> <p>Lastly, update the <code>output.schema.json</code> to return the expected results. This file will be validated against the output to ensure that the results (see line 180 in the previous code snippet) adhere to the output schema.</p> <p>In this algorithm, the expected output will be stored in a list (or array) named <code>my_expected_results</code>.  There must be at least 10 items in the list, and the items must have the type <code>number</code> (as shown in the highlighted lines).</p> output.schema.json<pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"my_expected_results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"my_expected_results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"array\",\n\"minItems\": 10,\n\"items\": {\"type\": \"number\"}\n}\n}\n}\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#run-the-test","title":"Run the test","text":"<p>First, update <code>__main__.py</code> with your sample data, model and ground truth files required for your algorithm to run.</p> <p>In this algorithm, we have updated the <code>data_path</code>, <code>model_path</code>, <code>ground_truth_path</code> to the path of the files. The <code>ground_truth</code> has also been set to default. We have also updated the <code>plugin_argument_values</code> with required arguments to ensure that the input validation passes. This is typically an input parameter from the dataset. For the mock data, we will be using gender as the plugin argument value.</p> <p>If you created the algorithm component with cookiecutter but did not use the recommended directory structure, you only need to point the <code>core_modules_path</code> to the test-engine-core-modules folder in step 1 of the Installing AI Verify Developer Tools page. If you followed the recommended directory structure, you can leave the <code>core_modules_path</code> as an empty string.</p> __main__.py<pre><code>from tests.plugin_test import PluginTest\nif __name__ == \"__main__\":\n# TODO: Define data, model, ground_truth file location. Requires absolute path.\n#       Define core modules path as relative/absolute path. If you cloned the project using \n#       the provided setup script, leave core_modules_path as an empty string.\n# Example:\n# data_path = \"tests/user_defined_files/data/pickle_pandas_mock_binary_classification_credit_risk_testing.sav\"\n# model_path = \"tests/user_defined_files/model/binary_classification_mock_credit_risk_sklearn.linear_model._logistic.LogisticRegression.sav\"\n# ground_truth = \"default\"\n# model_type = ModelType.CLASSIFICATION\ncore_modules_path = \"\"\ndata_path = \"tests/user_defined_files/data/pickle_pandas_mock_binary_classification_credit_risk_testing.sav\"\nmodel_path = \"tests/user_defined_files/model/binary_classification_mock_credit_risk_sklearn.linear_model._logistic.LogisticRegression.sav\"\nground_truth_path = \"tests/user_defined_files/data/pickle_pandas_mock_binary_classification_credit_risk_testing.sav\"\nground_truth = \"default\"\nmodel_type = ModelType.CLASSIFICATION\nrun_pipeline = False\n# TODO: Define the plugin input parameters value referenced from input.schema.json\n# Example:\n# plugin_arguments_value = {\n#     \"argument1\": \"MyArgumentValue\"\n# }\nplugin_argument_values = {\n\"feature_name\": \"gender\"\n}\n</code></pre> <p>Note</p> <p>Ground truth is optional so if your algorithm does not require ground truth, <code>ground_truth_path</code> and <code>ground_truth</code> can be left as an empty string <code>\"\"</code>.</p> <p>Next, run <code>python</code> to test your algorithm.</p> <pre><code>python .\n</code></pre> <p>If the test passes (no error messages in terminal), you have successfully completed the creation of the algorithm component. At this stage, you can either deploy your algorithm component as a standalone plugin, or continue to work on other components (eg. another algorithm, widget, input block etc) before packaging it as a single plugin.</p> <p>If the test fails, refer to the troubleshooting guide for help.</p>"},{"location":"guided_example/your_first_widget/","title":"Creating your First Widget Component","text":"<p>There are three learning objectives in this tutorial:</p> <ol> <li>Create a widget component in the existing plugin project.</li> <li>Modify the widget component to display the results from the completed algorithm component</li> <li>Deploy the widget component</li> </ol>"},{"location":"guided_example/your_first_widget/#generating-a-widget-component","title":"Generating a widget component","text":"<p>Widgets are stored in the template_plugin/widgets folder. Use ai-verify-plugin gw to generate your widget.</p> <p>Run the following command to generate a new widget and create a dependency to the algorithm component created earlier.</p> <pre><code>cd template_plugin/widgets\nai-verify-plugin gw \"mywidget\" --name \"My Widget\" --description \"A Widget\" --dep \"Algorithm,your_first_algorithm_component\"\n</code></pre> <p>Open the file <code>mywidget.meta.json</code> in the widgets folder and check that the properties are set correctly as shown below:</p> <pre><code>{\n\"cid\": \"mywidget\",\n\"widgetSize\": {\n\"minW\": 1,\n\"minH\": 1,\n\"maxW\": 12,\n\"maxH\": 36\n},\n\"name\": \"My Widget\",\n\"description\": \"A Widget\",\n\"dependencies\": [\n{\n\"cid\": \"your_first_algorithm_component\"\n}\n],\n\"mockdata\": [\n{\n\"type\": \"Algorithm\",\n\"cid\": \"your_first_algorithm_component\",\n\"datapath\": \"your_first_algorithm_component.sample.json\"\n}\n]\n}\n</code></pre>"},{"location":"guided_example/your_first_widget/#editing-sample-file","title":"Editing sample file","text":"<p>Open and edit <code>your_first_algorithm_component.sample.json</code> with a valid sample output from the algorithm or input block. This sample data will be passed to the MDX component props in the project canvas, and allows the MDX to display data based on sample input.</p> <pre><code>{\"my_expected_results\": [\n33280.0,\n40000.0,\n70000.0,\n50000.0,\n50000.0,\n40000.0,\n50000.0,\n0.0,\n90000.0,\n35000.0,\n80000.0,\n50000.0\n]    }\n</code></pre>"},{"location":"guided_example/your_first_widget/#editing-mdx","title":"Editing MDX","text":"<p>Open and edit <code>mywidget.mdx</code> to implement the MDX content.</p> <pre><code>export const cid = \"your_first_algorithm_component\"\n{props.getResults(cid)?(\n&lt;&gt;\n&lt;b&gt;JSON output of algorithm&lt;/b&gt;\n&lt;div style={{ maxHeight:\"100px\", overflow:\"auto\" }}&gt;{JSON.stringify(props.getResults(cid))}&lt;/div&gt;\n&lt;/&gt;\n):(\n&lt;div&gt;No data&lt;/div&gt;\n)}\n</code></pre> <p>Once you are done with the widget creation, you can proceed to deploy your plugin.</p>"},{"location":"plugins/","title":"Plugin System","text":""},{"location":"plugins/#description","title":"Description","text":"<p>This section documents the plugin system of AI Verify. </p>"},{"location":"plugins/#list-of-documentation-for-the-plugin-system-of-ai-verify","title":"List of Documentation for the Plugin System of AI Verify","text":"<ol> <li>Algorithm</li> <li>Widget &amp; Input Block</li> <li>Report Template</li> </ol>"},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/","title":"In-Depth Reference","text":""},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#understanding-your-installed-packages","title":"Understanding Your Installed Packages","text":""},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#zip","title":"zip","text":"<p><code>zip</code> is a package which compresses and packages a directory into a <code>.zip</code> file. We will be using <code>zip</code> to package the algorithm plugin into a distributable package. To install the package: <pre><code>sudo apt install -y zip\n</code></pre></p>"},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#jq","title":"jq","text":"<p><code>jq</code> is a package which does JSON processing. We will be using <code>jq</code> to extract fields from a JSON configuration file.  To install the package: <pre><code>sudo apt install -y jq\n</code></pre></p>"},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#cookiecutter","title":"Cookiecutter","text":"<p><code>Cookiecutter</code> is a command-line utility Python package that helps with creating projects from project templates. We will be using <code>Cookiecutter</code> to create the algorithm project from our predefined template.  To install Cookiecutter using pip or pip3: <pre><code>pip install cookiecutter\n</code></pre> You can try creating your own Cookiecutter template. Refer to tutorial for more information.</p>"},{"location":"plugins/algorithm/core_modules/","title":"Understanding the Core Modules","text":"<p>The core modules are custom packages that support different types of models, model pipelines, serialized data and data. When you run your algorithm, we will read in your model and data files. We will then traverse the <code>test_engine_core_modules</code> directory and see if there are support packages to handle the model and data files. If there are, we will be able to process the data correctly.  </p> <p>There are four categories of support for algorithms:  </p>"},{"location":"plugins/algorithm/core_modules/#model","title":"Model","text":"<p>Models are frameworks that are run by algorithms.  </p> <p>Models currently supported:</p> <ul> <li>LightGBM</li> <li>scikit-learn</li> <li>XGBoost </li> </ul>"},{"location":"plugins/algorithm/core_modules/#model-pipeline","title":"Model Pipeline","text":"<p>Model pipelines are models which apply a list of transforms and final estimator to the data.</p> <p>Model pipelines currently supported:</p> <ul> <li>scikit-learn</li> </ul>"},{"location":"plugins/algorithm/core_modules/#deserializer","title":"Deserializer","text":"<p>Deserializers process serialized data and make them into readable objects. Model and data files can sometimes be passed in as a serialized file type (e.g. Joblib). A serialized file is not easily readable and modifiable by humans. If we have the right deserializer for the serialized file, it wil deserialize the file into an object like Pandas dataframe, which users are able to modify.  </p> <p>Deserializers currently supported:</p> <ul> <li>Delimiter</li> <li>Joblib</li> <li>Pickle</li> <li>TensorFlow</li> <li>Image</li> </ul> <p></p>"},{"location":"plugins/algorithm/core_modules/#data-type","title":"Data Type","text":"<p>Data type refers to the type of data after it has been deserialized. If the data passed in does not require deserializing (e.g. the data file is <code>csv</code> file), the data type will be whatever is in the data file. Data types currently supported:</p> <ul> <li>Delimiter (colon, comma, pipe, semicolon, space, tab separated values)</li> <li>Pandas</li> <li>Image (JPG, JPEG, PNG) </li> </ul>"},{"location":"plugins/algorithm/deploying_algorithm/","title":"Deploying","text":""},{"location":"plugins/algorithm/deploying_algorithm/#deploying-and-packaging-your-algorithm-plugin","title":"Deploying and Packaging Your Algorithm Plugin","text":"<p>When you are creating your distribution package with <code>deploy_plugin.sh</code>, these are the things that will happen:  </p>"},{"location":"plugins/algorithm/deploying_algorithm/#syntax-checking","title":"Syntax checking","text":"<p>There will be a syntax check run on the main Python file (in this case it will be <code>your_first_algorithm_plugin.py</code>). This is to ensure that the algorithm can run smoothly before packaging. If the check fails, it means that there are syntax error(s) and you will have to fix the error(s) before continuing.  </p>"},{"location":"plugins/algorithm/deploying_algorithm/#test-running-the-algorithm","title":"Test Running the Algorithm","text":"<p>This is the same as testing your algorithm in the previous section. The algorithm's input argument(s) and generated results will be validated against the schema you have defined in <code>input.schema.json</code> and <code>output.schema.json</code> respectively. This is to ensure that the input argument(s) and generated results have the right format and data type.  </p>"},{"location":"plugins/algorithm/deploying_algorithm/#adding-in-the-required-files","title":"Adding in the Required Files","text":"<p>There is a predefined list of files that are required (as mentioned in requiredFiles) to be packaged with the algorithm plugin for the algorithm to run. The Python file(s)/directory(s) you have added into <code>requiredFiles</code> will be added into the package as well.  </p>"},{"location":"plugins/algorithm/deploying_algorithm/#packaging-the-algorithm-plugin","title":"Packaging the Algorithm Plugin","text":"<p>When all the checks have passed and all the required files have been added, the algorithm plugin, together with the required files, will be zipped into a <code>.zip</code> file and placed in the directory <code>dist</code>. The <code>.zip</code> package will be used for distribution.  </p>"},{"location":"plugins/algorithm/file_structure/","title":"Understanding Your Algorithm Project","text":""},{"location":"plugins/algorithm/file_structure/#project-directory","title":"Project Directory","text":"<p>After creating the project from Cookiecutter (with <code>your_first_algorithm_plugin</code> as an example), the project directory will look something like this: <pre><code>\u251c\u2500\u2500 AUTHORS.rst\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 __main__.py\n\u251c\u2500\u2500 input.schema.json\n\u251c\u2500\u2500 output.schema.json\n\u251c\u2500\u2500 plugin.meta.json\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 syntax_checker.py\n\u251c\u2500\u2500 tests\n\u2502   \u251c\u2500\u2500 plugin_test.py\n\u2502   \u2514\u2500\u2500 user_defined_files\n\u2502       \u251c\u2500\u2500 data\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_binary_classification_credit_risk_testing.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_binary_classification_pipeline_credit_risk_testing.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_binary_classification_pipeline_credit_risk_ytest.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_multiclass_classification_pipeline_toxic_classification_testing.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_multiclass_classification_pipeline_toxic_classification_ytest.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_multiclass_classification_toxic_classification_testing.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_regression_donation_testing.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_regression_pipeline_testing.sav\n\u2502       \u2502   \u251c\u2500\u2500 pickle_pandas_mock_regression_pipeline_ytest.sav\n\u2502       \u2502   \u2514\u2500\u2500 raw_fashion_image_10\n\u2502       \u2502       \u251c\u2500\u2500 0.png\n\u2502       \u2502       \u251c\u2500\u2500 1.png\n\u2502       \u2502       \u251c\u2500\u2500 2.png\n\u2502       \u2502       \u251c\u2500\u2500 3.png\n\u2502       \u2502       \u251c\u2500\u2500 4.png\n\u2502       \u2502       \u251c\u2500\u2500 5.png\n\u2502       \u2502       \u251c\u2500\u2500 6.png\n\u2502       \u2502       \u251c\u2500\u2500 7.png\n\u2502       \u2502       \u251c\u2500\u2500 8.png\n\u2502       \u2502       \u2514\u2500\u2500 9.png\n\u2502       \u251c\u2500\u2500 model\n\u2502       \u2502   \u251c\u2500\u2500 binary_classification_mock_credit_risk_sklearn.linear_model._logistic.LogisticRegression.sav\n\u2502       \u2502   \u251c\u2500\u2500 multiclass_classification_mock_toxic_classification_sklearn.linear_model._logistic.LogisticRegression.sav\n\u2502       \u2502   \u2514\u2500\u2500 regression_mock_donation_sklearn.linear_model._base.LinearRegression.sav\n\u2502       \u2514\u2500\u2500 pipeline\n\u2502           \u251c\u2500\u2500 binary_classification_tabular_credit_loan\n\u2502           \u2502   \u251c\u2500\u2500 binary_classification_pipeline_credit_risk_sklearn.pipeline.Pipeline.sav\n\u2502           \u2502   \u2514\u2500\u2500 creditCustomClass.py\n\u2502           \u251c\u2500\u2500 multiclass_classification_image_mnist_fashion\n\u2502           \u2502   \u251c\u2500\u2500 fashionCustomClass.py\n\u2502           \u2502   \u2514\u2500\u2500 fashion_mnist_lr_pipeline.sav\n\u2502           \u251c\u2500\u2500 multiclass_classification_tabular_toxic_classification\n\u2502           \u2502   \u251c\u2500\u2500 multiclass_classification_pipeline_toxic_classification_sklearn.pipeline.Pipeline.sav\n\u2502           \u2502   \u2514\u2500\u2500 toxicCustomClass.py\n\u2502           \u2514\u2500\u2500 regression_tabular_donation\n\u2502               \u251c\u2500\u2500 regressionCustomClass.py\n\u2502               \u2514\u2500\u2500 regression_pipeline_donation_sklearn.pipeline.Pipeline.sav\n\u251c\u2500\u2500 your_first_algorithm_plugin.meta.json\n\u2514\u2500\u2500 your_first_algorithm_plugin.py\n</code></pre></p>"},{"location":"plugins/algorithm/file_structure/#files-in-the-project","title":"Files in The Project","text":"<ul> <li><code>AUTHORS.rst</code> The name or organisation name of the algorithm developer.</li> <li><code>CHANGELOG.md</code> A log of all notable changes made to this project.</li> <li><code>LICENSE</code> The license of this algorithm.</li> <li><code>README.md</code> A default page which is shown on the code repository. It contains the description, license, plugin URL and developers.</li> <li><code>__main__.py</code> The file with a main function which serves as an entry point for testing. </li> <li><code>input.schema.json</code> The input schema of the algorithm. It is used to validate against the user's input when running the algorithm.</li> <li><code>output.schema.json</code> The output schema of the algorithm. It is used to validate against the algorithm's generated result.</li> <li><code>plugin.meta.json</code> The metadata of the algorithm. It contains the gid, version, name, author, description and project url.</li> <li><code>requirements.txt</code> A list of required Python packages required for this plugin.</li> <li><code>syntax_checker.py</code> A Python script which checks for syntax errors in the main file <code>your_first_algorithm_plugin.py</code>.</li> <li><code>tests/plugin_test.py</code> The file with all the testing logic of the algorithm plugin. It is called by <code>__main__.py</code>. </li> <li><code>tests/user_defined_files</code> A directory for the user to place all the test files required for the algorithm. Test files can include sample data and model read in by the algorithm. </li> <li><code>your_first_algorithm_plugin.meta.json</code> The metadata of the type of algorithm, which also serves as a configuration file to manage the files to include for deployment. It contains the cid, name, model type, version, description, tags, whether or not it requires ground truth and the required files for deployment. </li> <li><code>your_first_algorithm_plugin.py</code> The file with all the logic of the algorithm. Most, if not all the codes should reside in this file. </li> </ul>"},{"location":"plugins/algorithm/file_structure/#understanding-the-files-you-need-to-modify","title":"Understanding the Files You Need To Modify","text":"<p>While there are many files included in this project, you will only need to focus on modifying a few files. There are <code>TODO</code> comments in each of these files to guide you on the things you have to modify (please remove the <code>TODO</code> comments when you have modified the required parts). Here are the files:</p>"},{"location":"plugins/algorithm/file_structure/#__main__py","title":"<code>__main__.py</code>","text":"<p>The entry point when testing your algorithm. When you run <code>python .</code>, you will run this file, which will call the test file. You will need to update the paths to the data and the input arguments in this file. Example:  __main__.py<pre><code>    core_modules_path = \"\"\ndata_path = \"tests/user_defined_files/data/pickle_pandas_mock_binary_classification_credit_risk_testing.sav\"\nmodel_path = \"tests/user_defined_files/model/binary_classification_mock_credit_risk_sklearn.linear_model._logistic.LogisticRegression.sav\"\nground_truth_path = \"tests/user_defined_files/data/pickle_pandas_mock_binary_classification_credit_risk_testing.sav\"\nground_truth = \"default\"\nmodel_type = ModelType.CLASSIFICATION\nrun_pipeline = False\nplugin_argument_values = {\n\"sensitive_feature\": [\"gender\"]\n}\n</code></pre></p> <ul> <li><code>core_modules_path</code>: The absolute or relative path (from <code>__main__.py</code>) of the test-engine-core-modules path. This can be left empty and it will default to <code>../../../../test-engine-core-modules</code></li> <li><code>data_path</code>: The absolute or relative path (from <code>__main__.py</code>) of the test data file</li> <li><code>model_path</code>: The absolute or relative path (from <code>__main__.py</code>) of the test model file</li> <li><code>ground_truth_path</code> (optional): The absolute or relative path (from <code>__main__.py</code>) of the ground truth data file </li> <li><code>ground_truth</code>(optional): The field name(<code>string</code>) of the ground truth </li> </ul> <p>Note</p> <p>Ground truth is optional so if your algorithm does not require ground truth, <code>ground_truth_path</code> and <code>ground_truth</code> can be left as an empty string <code>\"\"</code>.</p> <ul> <li><code>plugin_argument_values</code>: A dictionary of input arguments. In the example above, the input argument <code>sensitive_feature</code>is an  <code>array</code> of <code>string</code> . The input argument(s) and their type(s) must match the schema in <code>input.schema.json</code>.  </li> </ul>"},{"location":"plugins/algorithm/file_structure/#your_first_algorithm_pluginpy","title":"<code>your_first_algorithm_plugin.py</code>","text":"<p>Note</p> <p>This section uses <code>your_first_algorithm_plugin</code> as a sample project. If, for instance, your project is named <code>your_second_algorithm_plugin</code>, this file would be named <code>your_second_algorithm_plugin.py</code> instead.</p> <p>This file is the heart of the algorithm plugin where the magic happens. Most, if not all the codes will be in this file. </p>"},{"location":"plugins/algorithm/file_structure/#plugin-description","title":"Plugin Description","text":"<p>The following points should be considered when writing the plugin description:</p> <ol> <li>Document the purpose of this plugin.</li> <li>What does this plugin do in general? </li> <li>Are there any limitations for this plugin?</li> <li> <p>Is there anything else that future developers should note or understand?     Example:</p> <pre><code>    \"\"\"\n    # TODO: Update the plugin description below\n    The Plugin({{cookiecutter.plugin_name}}) class specifies methods in generating results for algorithm\n    \"\"\"\n# Some information on plugin\n_name: str = \"Partial Dependence Plot\"\n_description: str = (\n\"A Partial Dependence Plot (PDP) explains how each feature and its feature value \"\n\"contribute to the predictions.\"\n)\n_version: str = \"0.1.0\"\n_metadata: PluginMetadata = PluginMetadata(_name, _description, _version)\n_plugin_type: PluginType = PluginType.ALGORITHM\n_requires_ground_truth: bool = False\n</code></pre> </li> </ol>"},{"location":"plugins/algorithm/file_structure/#input-schema","title":"Input Schema","text":"<pre><code>There is no need to update anything in this file. This is a reminder to update the `input.schema.json`.\n</code></pre>"},{"location":"plugins/algorithm/file_structure/#output-schema","title":"Output Schema","text":"<pre><code>There is no need to update anything in this file. This is a reminder to update the `output.schema.json`.\n</code></pre>"},{"location":"plugins/algorithm/file_structure/#main-codes-of-the-algorithm","title":"Main Codes of the Algorithm","text":"<p>The <code>generate()</code> method is where your codes will be inserted. When the main file <code>__main__.py</code> is run, it will create an instance of <code>PluginTest()</code> and call its method <code>run()</code>, which will call this method <code>generate()</code>. As such, your codes will be in either in <code>generate()</code> or another method that <code>generate()</code> calls, like <code>_explain_pdp()</code> in the example below:</p> <pre><code>      def generate(self) -&gt; None:\n\"\"\"\n        A method to generate the algorithm results with the provided data, model, ground truth information.\n        \"\"\"\n# Retrieve data information\nself._data = self._data_instance.get_data()\n# Perform pdp explanation\nself._explain_pdp()\n# Update progress (For 100% completion)\nself._progress_inst.update(1)\ndef _explain_pdp(self) -&gt; None:\n# main codes\n...\n...\nself._results = your_algo_output_results\n</code></pre> <p>Note</p> <p>Regardless of where your algorithm codes are placed, the final output of the algorithm must be assigned to <code>self._results</code>. The final output will be used to match against the schema defined in <code>output.schema.json</code>.</p> <p></p>"},{"location":"plugins/algorithm/file_structure/#inputschemajson","title":"<code>input.schema.json</code>","text":"<p>Specifies the schema for the input. This is used to validate the schema of the user's input. Example:</p> <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"title\": \"Sensitive Feature Names\",\n\"description\": \"Array of Sensitive Feature Names (e.g. Gender)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"string\"\n},\n\"minItems\": 1\n}\n}\n}\n</code></pre> <ul> <li><code>title</code>: The title of this input schema file </li> <li><code>description</code>: The description of this input schema file</li> <li><code>type</code>: Input type of argument. It should be <code>object</code> by default</li> <li><code>required</code>:  Field(s) which must be present. Add the name of the required field(s) into the list (i.e. <code>required: [required_feature_one, ... ,required_feature_n]</code>)</li> <li><code>properties</code>: Contains the details of the <code>required</code> field(s). Every <code>required</code> field must be included and contain the following details: <ul> <li><code>title</code>: Name of the required field</li> <li><code>description</code>: A brief description of the field with some sample </li> <li><code>type</code>: The type of the required field. It can be <code>array</code>, <code>string</code>, <code>number</code>, etc</li> <li>If the <code>type</code> is <code>array</code>, it must also contain a nested list named <code>items</code>, which contains the <code>type</code> of the element in the <code>array</code> (refer to <code>percentiles</code> in the example). You can include multiple types in the <code>items</code> list if you allow multiple types for the <code>items</code> (i.e. <code>\"items\": {\"type\": \"number\", \"type\": \"string\"}</code>)</li> </ul> </li> </ul> <p></p>"},{"location":"plugins/algorithm/file_structure/#outputschemajson","title":"<code>output.schema.json</code>","text":"<p>Specifies the schema for the output. This is used to validate the schema of the algorithm's output.  Example:  <pre><code>{\n\"title\":\"Algorithm Plugin Output Arguments\",\n\"description\":\"A schema for algorithm plugin output arguments\",\n\"type\":\"object\",\n\"required\":[\n\"feature_names\",\n\"results\"\n],\n\"properties\":{\n\"feature_names\":{\n\"type\":\"array\",\n\"description\":\"Array of feature names\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"string\"\n}\n},\n\"output_classes\":{\n\"description\":\"Array of output classes\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":[\n\"string\",\n\"number\",\n\"integer\",\n\"boolean\"\n]\n}\n},\n\"results\":{\n\"description\":\"Matrix of feature values (# feature names)\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"description\":\"Matrix of PDP plot data (# output classes)\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"array\",\n\"description\":\"Array of PDP values for each feature value (# feature values)\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"object\",\n\"description\":\"Array of feature and PDP value\",\n\"required\":[\n\"feature_value\",\n\"pdp_value\"\n],\n\"properties\":{\n\"feature_value\":{\n\"type\":\"number\"\n},\n\"pdp_value\":{\n\"type\":\"number\"\n}\n}\n}\n}\n}\n}\n}\n}\n</code></pre></p> <ul> <li><code>title</code>: The title of this output schema file </li> <li><code>description</code>: The description of this output schema file</li> <li><code>type</code>: Input type of argument. It should be <code>object</code> by default</li> <li><code>required</code>:  Field(s) which must be present. Add the name of the required field(s) into the list (i.e. <code>required: [required_feature_one, ... ,required_feature_n]</code>)</li> <li><code>properties</code>: Contains the details of the <code>required</code> field(s). Every <code>required</code> field must be included and contain the following details: <ul> <li><code>description</code>: A brief description of the field with some sample </li> <li><code>type</code>: The type of the required field. It can be <code>array</code>, <code>string</code>, <code>number</code>, etc </li> <li>If the <code>type</code> is <code>array</code>, it must also contain a nested list named <code>items</code>, which contains the <code>type</code> of the element in the <code>array</code> (refer to <code>output_classes</code> in the example). You can include multiple types in the <code>items</code> list if you allow multiple types for the <code>items</code> (i.e. <code>\"items\": {\"type\": \"number\", \"type\": \"string\"}</code>) </li> </ul> </li> </ul>"},{"location":"plugins/algorithm/file_structure/#your_first_algorithm_pluginmetajson","title":"<code>your_first_algorithm_plugin.meta.json</code>","text":"<p>The metadata of the algorithm plugin. This file should be autogenerated by Cookiecutter according to the your input during the creation phase. Example:</p> <pre><code>{\n\"cid\": \"partial_dependence_plot\",\n\"name\": \"Partial Dependence Plot\",\n\"modelType\": [\n\"classification\",\n\"regression\"\n],\n\"version\": \"0.9.0\",\n\"author\": \"AI Verify\",\n\"description\": \"A Partial Dependence Plot (PDP) explains how each feature and its feature value contribute to the predictions.\",\n\"tags\": [\n\"Partial Dependence Plot\",\n\"classification\",\n\"regression\"\n],\n\"requireGroundTruth\": false,\n\"requiredFiles\": [\n\"AUTHORS.rst\",\n\"CHANGELOG.md\",\n\"input.schema.json\",\n\"LICENSE\",\n\"output.schema.json\",\n\"partial_dependence_plot.meta.json\",\n\"partial_dependence_plot.py\",\n\"README.md\",\n\"requirements.txt\",\n\"syntax_checker.py\",\n\"my_additional_python_files_dir\",\n\"my_custom_python_file.py\"\n]\n}\n</code></pre> <ul> <li><code>cid</code>: The component name of the algorithm</li> <li><code>name</code>: The name of this algorithm plugin </li> <li><code>modelType</code>: The type(s) of the algorithm model. It can be either <code>classification</code>, <code>regression</code> or both </li> <li><code>version</code>: The version of this algorithm. It defaults to <code>0.1.0</code>. If this algorithm is an improvement of a previous algorithm, you should increase the version accordingly. Refer to Understanding Versioning for more information </li> <li><code>author</code>: The name of the developer or the developer's organisation </li> <li><code>description</code>: A short description on what the algorithm does </li> <li><code>tags</code>: A list of searchable tag(s) for the algorithm (i.e. you can add <code>classification</code> to this list if the algorithm supports it) </li> <li><code>requiresGroundTruth</code>: A boolean value to determine if this algorithm requires ground truth data </li> <li><code>requiredFiles</code>: A list of required files for the algorithm to run. If you have other required file(s) (currently we only allow <code>.py</code> files), add the file name into this list <ul> <li>If the <code>.py</code> file(s) are in a directory, you can add the directory into the list. The directory will be recursively traversed and all the discovered <code>.py</code> files will be added, with the directory hierarchy preserved<ul> <li>For example, <code>my_additional_python_files_dir</code> and <code>my_custom_python_file.py</code> are additional required directory and Python file  added in by the user</li> </ul> <p>Note</p> <p>Do not remove or edit the required files already in the list </p> </li> </ul> </li> </ul>"},{"location":"plugins/algorithm/file_structure/#requirementstxt","title":"<code>requirements.txt</code>","text":"<p>Python requirements file is used to keep track of the Python packages used by this algorithm plugin. It simplifies the installation of all required packages and makes it easy to share your project with others. Example: </p> <p><pre><code>numpy==1.24.2 ; python_version &gt;= \"3.10\" and python_version &lt; \"3.12\"\nscipy==1.10.1 ; python_version &gt;= \"3.10\" and python_version &lt; \"3.12\"\n</code></pre> This file should be updated if there are changes to the required Python packages. </p> <p>Example of how to generate requirements.txt: 1. Using pip or pip3 to generate requirements.txt: <pre><code>pip freeze &gt; requirements.txt\n</code></pre> 2. Using a Python packaging and dependency management tool such as Poetry: <code>bash    poetry export --without-hashes --format=requirements.txt &gt; requirements.txt</code> </p>"},{"location":"plugins/algorithm/testing_algorithm/","title":"Testing Your Algorithm","text":"<p>When you run your algorithm, certain tests are carried out:</p>"},{"location":"plugins/algorithm/testing_algorithm/#running-the-data-model-and-ground-truth-files","title":"Running the Data, Model and Ground Truth Files","text":"<p>You will require at least the data and model files to run your algorithm. The files will be read. If the data and/or model cannot be supported, there will be an error message and the algorithm will not be run. </p>"},{"location":"plugins/algorithm/testing_algorithm/#validating-the-input-arguments","title":"Validating the Input Arguments","text":"<p>The algorithm's input argument(s) will be validated against the schema you have defined in <code>input.schema.json</code>. This is to ensure that the input argument(s) have the right format and data type. </p>"},{"location":"plugins/algorithm/testing_algorithm/#validating-the-generated-output","title":"Validating the Generated Output","text":"<p>After running the algorithm, the generated results will be validated against the schema you have defined in <code>output.schema.json</code>. This is to ensure that the generated results from the algorithm have the right format and data type. </p>"},{"location":"plugins/create-algorithm-plugins/create-algorithm-plugins-intro/","title":"Plugin Development Guide","text":"<p>A plugin, short for \"plug-in\" or \"add-on\", is a piece of software that adds a specific functionality or feature to an existing application or system.  Plugins are typically designed to extend the functionality of an existing program, without requiring the user to modify or recompile the original application code.</p> <p>This plugin development guide aims to help algorithm developers to build their own algorithm(s) plugin that adds a new algorithm or capability to the A.I. Verify.</p> <p>Note</p> <p>Before developing your own plugin, it is best to visit our existing plugins to check if it is already available for use.</p> <p>In this section, we are covering topics to be proficient in developing algorithm plugins:</p> <ul> <li>Create your first algorithm plugin    This subsection will help developers follow through the creation phase and develop their first algorithm plugin    which reads in a string input and returns the input string.  </li> <li>In-depth reference    This subsection will help developers read in more details about the generated    files and knowing how the whole algorithm plugin work.  </li> <li>Advanced Topics    This subsection will discuss on advanced topics that developers might need    while developing your own algorithm plugins.  </li> <li>Samples    This subsection will provide samples for developers to reference.</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/","title":"Create Your First Algorithm Plugin","text":"<p>This guide shows you how to create an algorithm plugin and deploy/package it into a distributable file that can be  shared with other users using the test-engine-algo-plugin-template project.</p> <p>The easiest way to understand what an algorithm plugin can do is to create one and see how it works.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#prerequisites","title":"Prerequisites","text":"<p>Before we can do anything in this example, you must have Ubuntu, Python and some dependency packages installed on your machine.  Look below for the necessary OS and packages:</p> <ul> <li> <p>Ubuntu 22.04.2 LTS (Jammy Jellyfish)  This Linux platform is recommended for our plugin development to ensure the perfect plugin creation experience.</p> </li> <li> <p>Python 3.10  This package is compulsory. Python is a programming language that lets you  work more quickly and integrate your systems more effectively.</p> </li> <li> <p>Cookiecutter  This package is a command-line utility that creates projects from cookiecutters (project templates),  e.g. creating a Python package project from a Python package project template. <code>$ pip install --user cookiecutter</code></p> </li> <li> <p>jq  This package is like <code>sed</code> for JSON data. It is a lightweight and flexible command-line JSON processor. <code>$ sudo apt install -y jq</code></p> </li> <li> <p>zip  This package is a command-line utility that provides packaging and compressing (archive) files. <code>$ sudo apt install -y zip</code></p> </li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#see-also","title":"See Also","text":"<ul> <li>Understanding Your Installed Packages</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#your-first-algorithm-plugin","title":"Your First Algorithm Plugin","text":""},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#getting-started","title":"Getting Started","text":"<p>To get started, open a <code>terminal</code> on your computer.</p> <p>Then, we will create a copy of the test-engine-algo-plugin-template project. This project is a Cookiecutter template which generates the base algorithm plugin for modification.  <pre><code>$ cookiecutter https://gitlab.com/imda_dsl/t2po/ai-verify/ai-verify-test-engine/test-engine-algo-plugin-template.git\n</code></pre></p> <p>You will be presented with a couple of questions:</p> <ul> <li>author [example_author]: We will use the default. Press Enter.</li> <li>plugin_name [example plugin]: Our plugin name will be called <code>your-first-algorithm-plugin</code>. Press Enter.</li> <li>Choose from 1 [1]: We will use the default. Press Enter.</li> <li>plugin_version [0.1.0]: We will use the default. Press Enter.</li> <li>plugin_description [My example plugin]: Our plugin description will be called <code>Your first algorithm plugin</code>. Press Enter.</li> <li>Select license [1]: We will use the default. Press Enter.</li> <li>Select algo_model_support [1]: We will use the default. Press Enter.</li> <li>Select require_ground_truth [1]:  Our plugin will not need ground_truth. Select 2. Press Enter. </li> </ul> <p>Note</p> <p>The plugin name <code>your-first-algorithm-plugin</code> will automatically be converted to <code>your_first_algorithm_plugin</code>.  The cookiecutter generator will automatically convert the name to create the project slug. Refer to the guide on Package and Module Names.</p> <p>Verify that the directory <code>your_first_algorithm_plugin</code> exists in your current directory: <pre><code>ls | grep your_first_algorithm_plugin\n</code></pre></p> <p> If you do not see the project name, something in the setup is incomplete. Please re-create the project directory through the steps above again.   Yay! You have instantly generated a algorithm plugin project! </p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#see-also_1","title":"See Also","text":"<ul> <li>Understanding Your Algorithm Project</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#building-the-algorithm-plugin","title":"Building the Algorithm Plugin","text":"<p>Before we start, we should create a virtual environment (venv) to let the project have its independent set  of Python packages. The virtual environment can be anywhere (remember where you put it as you will need to activate it) <pre><code>python3 -m venv my_virtual_environment\n</code></pre></p> <p>Now that we have created this virtual environment for the project, cd to the directory with the virtual environment and activate it. <pre><code>source my_virtual_environment/bin/activate\n</code></pre></p> <p>We can see that the environment is activated with the <code>(my_virtual_environment)</code>: </p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#installing-the-core-library","title":"Installing the Core Library","text":"<p>Note</p> <p>Before we install the other libraries, ensure that your virtual environment is activated.</p> <p>There is a custom core library required to build algorithms. </p> <p>To download the library, clone the project from our Gitlab repository: <pre><code>$ git clone https://gitlab.com/imda_dsl/t2po/ai-verify/ai-verify-test-engine/test-engine-core.git --branch dev_main\n</code></pre></p> <p>To install the library, cd to the <code>test-engine-core</code> directory: <pre><code>$ pip install dist/test_engine_core-1.0.0.tar.gz\n</code></pre></p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#installing-prerequisites-for-additional-developers-support","title":"Installing Prerequisites for Additional Developers Support","text":"<p>We have provided additional developers support for reading data files, model files, and serializers. To access these supported tools, you will need to run the script that installs the package requirements.</p> <p>First, you will need to navigate to the project directory: <pre><code>$ cd your_first_algorithm_plugin/\n</code></pre></p> <p>Next, run the <code>tests/install_core_modules_requirements.sh</code> script to install the packages listed in the <code>core_modules</code> directory: (This may take some time) <pre><code>$ tests/install_core_modules_requirements.sh\n</code></pre></p> <p>An example of the installation script running: </p> <p>Now that the script has installed the packages successfully, you can read in data, model files  and manipulate the information and work on the algorithm.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#see-also_2","title":"See Also","text":"<ul> <li>Understanding the Core Modules </li> <li>Understanding Your Algorithm Project</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#developing-the-algorithm-plugin","title":"Developing the algorithm plugin","text":"<p>First, let us try to understand the algorithm plugin that we are trying to implement. Our generated algorithm plugin will take in a sample data, model, ground truth path and ground truth field by default. We will modify the codes to read in the sample data from the sample data path, and the sample model from the  sample model path.   Then, we will request the user to input a feature name which he/she wants to retrieve the data for output.  Finally, we will return the output, which is the data for the requested feature.</p> <p> Now that we are clear on what we want to achieve for this algorithm plugin, open your favorite IDE or text editor to navigate to the project. There are multiple files and directories in the project, but we will focus on a few that will help us create our first algorithm plugin.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#inputschemajson","title":"input.schema.json","text":"<p>First, we will request for the feature name from the user. In this JSON file, we will request for information for our algorithm to work properly.</p> <p>Let us modify the JSON to read in the <code>feature_name</code>:</p> <p>input.schema.json<pre><code>{\n\"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n\"$id\": \"https://pypi.org/project/example_plugin//input.schema.json\",\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_name\"\n],\n\"properties\": {\n\"feature_name\": {\n\"title\": \"Feature Name\",\n\"description\": \"Indicate the feature name (e.g. Interest_Rate) to be extracted from data file\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre> Notice the highlighted lines that requires a <code>feature_name</code> field, and the properties of the <code>feature_name</code> is also defined.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference","title":"Reference","text":"<ul> <li>Fields for input.schema.json</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#your_first_algorithm_pluginpy","title":"your_first_algorithm_plugin.py","text":"<p>Next, we will write the logic to retrieve the information of the requested feature. The generated codes have <code>TODO:</code> comments for users to quickly navigate to places that require modification.</p> <p>TODO #1: <code># TODO: Update the plugin description below</code> This <code>TODO</code> is a reminder that you may need to update the plugin description. We will leave it for now:</p> <p>your_first_algorithm_plugin.py<pre><code>class Plugin(IAlgorithm):\n\"\"\"\n    # TODO: Update the plugin description below\n    The Plugin(your-first-algorithm-plugin) class specifies methods in generating results for algorithm\n    \"\"\"\n# Some information on plugin\n_name: str = \"your-first-algorithm-plugin\"\n_description: str = \"Your first algorithm plugin\"\n_version: str = \"0.1.0\"\n_metadata: PluginMetadata = PluginMetadata(_name, _description, _version)\n_plugin_type: PluginType = PluginType.ALGORITHM\n_requires_ground_truth: bool = False\n</code></pre> </p> <p>TODO #2: <code># TODO: Update the input json schema in input.schema.json</code> This <code>TODO</code> is a reminder that you need to update the input json schema to get your user input parameters We have updated it in the previous step while requesting for <code>feature_name</code>: your_first_algorithm_plugin.py<pre><code>        # Other variables\nself._data = None\nself._results = {\"results\": [0]}\n# TODO: Update the input json schema in input.schema.json\n# Algorithm input schema defined in input.schema.json\n# By defining the input schema, it allows the front-end to know what algorithm input params is\n# required by this plugin. This allows this algorithm plug-in to receive the arguments values it requires.\nself._input_schema = load_schema_file(\nstr(self._base_path / \"input.schema.json\")\n)\n</code></pre> </p> <p>TODO #3: <code># TODO: Update the output json schema in output.schema.json</code> This <code>TODO</code> is a reminder that you need to update the output json schema validate your output. We will update this later. your_first_algorithm_plugin.py<pre><code>    # TODO: Update the output json schema in output.schema.json\n# Algorithm output schema defined in output.schema.json\n# By defining the output schema, this plug-in validates the result with the output schema.\n# This allows the result to be validated against the schema before passing it to the front-end for display.\nself._output_schema = load_schema_file(\nstr(self._base_path / \"output.schema.json\")\n)\n</code></pre> </p> <p>TODO #4: <code># TODO: Insert algorithm logic for this plug-in.</code> This <code>TODO</code> is a reminder that you need to insert your algorithm logic here. In this <code>TODO</code>, we will read the user defined feature name.  As we have defined earlier on that the input schema indicates that the algorithm requires the 'feature name'.  We can now read the requested input argument.</p> <p>After we can retrieve the user input feature name, we can now use this to read the values under this feature name. After reading the values, we convert it into a list to be returned. The algorithm results have to be stored in the <code>self._results</code> variable for the result to be returned.</p> <p>You might have noticed that the <code>self._results</code> is <code>Dict</code>, and the key is <code>my_expected_results</code>. Later in the output schema json section, it shows why we need to have the key as <code>my_expected_results</code>. </p> <p>Note</p> <p>Code examples does not include error checking functionality.</p> your_first_algorithm_plugin.py<pre><code>    def generate(self) -&gt; None:\n\"\"\"\n        A method to generate the algorithm results with the provided data, model, ground truth information.\n        \"\"\"\n# Retrieve data information\nself._data = self._data_instance.get_data()\n# TODO: Insert algorithm logic for this plug-in.\n# Retrieve the input arguments\nmy_user_defined_feature_name = self._input_arguments['feature_name']\n# Get the values of the feature name and convert to a list.\nself._results = {\n\"my_expected_results\": list(self._data[my_user_defined_feature_name].values)\n}\n# Update progress (For 100% completion)\nself._progress_inst.update(1)\n</code></pre>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference_1","title":"Reference","text":"<ul> <li>Modifying your_first_algorithm_plugin.py</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#outputschemajson","title":"output.schema.json","text":"<p>Lastly, we will validate the algorithm's output against the schema defined in this file. This is to ensure that the output has the expected fields and types defined in the schema. </p> <p>Let us modify the JSON to define the schema of the expected output.</p> <p>output.schema.json<pre><code>{\n\"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n\"$id\": \"https://pypi.org/project/example_plugin//output.schema.json\",\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"my_expected_results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"my_expected_results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"array\",\n\"minItems\": 10,\n\"items\": {\"type\": \"number\"}\n}\n}\n}\n</code></pre> The expected output will be stored in a list (or array) named <code>my_expected_results</code>.  There must be at least 10 items in the list, and the items must have the type <code>number</code> (as shown in the highlighted lines).</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference_2","title":"Reference","text":"<ul> <li>Fields for output.schema.json</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#testing-the-algorithm-plugin","title":"Testing the algorithm plugin","text":"<p>Once you are done with your algorithm, it is time to test it with some data and model. To run the test, you will need to modify the main file to read the data, model and ground truth files required for your algorithm to run.</p> <p>__main__.py<pre><code>from tests.plugin_test import PluginTest\nif __name__ == \"__main__\":\n# TODO: Define data, model, ground_truth file location. Requires absolute path.\n# Example:\n# data_path = \"tests/user_defined_files/my_data_file.sav\"\n# model_path = \"tests/user_defined_files/my_model_file.sav\"\n# ground_truth_path = \"tests/user_defined_files/my_ground_truth_file.sav\"\n# ground_truth = \"Interest_Rate\"\ndata_path = \"tests/user_defined_files/sample_data.sav\"\nmodel_path = \"tests/user_defined_files/sample_model.sav\"\nground_truth_path = \"\"\nground_truth = \"\"\n# TODO: Define the plugin input parameters value referenced from input.schema.json\n# Example:\nplugin_argument_values = {\n\"feature_name\": \"Annual_Income\"\n}\n</code></pre> In the example above, we have updated the <code>data_path</code>, <code>model_path</code>, <code>ground_truth_path</code> and <code>ground_truth</code> to the path of the files. We have also updated the <code>plugin_argument_values</code> with the required argument defined in input.schema.json to ensure that the input validation passes.</p> <p>Note</p> <p>Ground truth is optional so if your algorithm does not require ground truth, <code>ground_truth_path</code> and <code>ground_truth</code> can be left as an empty string <code>\"\"</code>.</p> <p>After you have updated the file paths, change directory to the directory with <code>__main__.py</code> and run the test using python or python3: <pre><code>python .\n</code></pre> If the test passes (no error messages in terminal), you are ready to move to the next step to deploy your algorithm plugin. If the test fails, refer to the troubleshooting guide for help.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference_3","title":"Reference","text":"<ul> <li>Variables in main.py</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#deploying-the-algorithm-plugin","title":"Deploying the Algorithm Plugin","text":"<p>We have provided a script to help deploy your algorithm plugin by packaging it. To run the script, change directory to the directory with the script <code>deploy_plugin.sh</code> and enter: <pre><code>./deploy_plugin.sh\n</code></pre></p> <p>Note</p> <p>A new folder <code>dist</code> will be created. This folder is where the packaged <code>.zip</code> file will be created and placed.</p> <p>Verify that the zip file <code>your_first_algorithm_plugin-0.1.0.zip</code> exists in your <code>dist</code> directory: <pre><code>ls dist | grep your_first_algorithm_plugin\n</code></pre></p> <p>We can see that the is a generated <code>zip</code> file which can be used to share with other developers who are interested in using your algorithm. </p> <p>Congratulations! You have successfully completed your first algorithm plugin! Now that you have learnt how to create your own algorithm plugin, request for input arguments to your algorithm,  know where to write your algorithm magic and retrieve information from user, output the results based on your schema,  perform testing on your algorithm plugin and deploying it for sharing, you should start building more complex algorithm plugins.</p> <p>You may want to check out the Advanced section of the guide.</p>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/","title":"Algorithm - Accumulated Local Effects","text":""},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#description","title":"Description","text":"<ul> <li>Performs ALE Discrete and ALE Continuous computation</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#plugin-url","title":"Plugin URL","text":"<ul> <li>Accumulated Local Effects - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/","title":"Algorithm - Fairness Metrics Toolbox","text":""},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#description","title":"Description","text":"<ul> <li>The Fairness Metrics Toolbox (FMT) contains a list of fairness metrics to measure how resources (e.g. opportunities, food, loan, medical help) are allocated among the demographic groups (e.g. married male, married female) given a set of sensitive feature(s) (e.g. gender, marital status).</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#plugin-url","title":"Plugin URL","text":"<ul> <li>Fairness Metrics Toolbox - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/","title":"Algorithm - Partial Dependence Plot","text":""},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#description","title":"Description","text":"<ul> <li>A Partial Dependence Plot (PDP) explains how each feature and its feature value contribute to the predictions.</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#plugin-url","title":"Plugin URL","text":"<ul> <li>Partial Dependence Plot - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/","title":"Algorithm - Performance Metrics Toolbox","text":""},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#description","title":"Description","text":"<ul> <li>This plugin generates the performance metrics of the model given the set of test dataset.</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#plugin-url","title":"Plugin URL","text":"<ul> <li>Performance Metrics Toolbox - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/","title":"Algorithm - SHAP Toolbox","text":""},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#description","title":"Description","text":"<ul> <li>SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations).</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#plugin-url","title":"Plugin URL","text":"<ul> <li>SHAP Toolbox - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/widget/","title":"AI Verify Plugin","text":"<p>This section contains documentations for widget and input block developers as well as the ai-verify-plugin tool.</p>"},{"location":"plugins/widget/#documentation-and-references","title":"Documentation and References","text":"<ul> <li>Plugin - Explains what is AI Verify Plugin and it's structure</li> <li>Widget - Describes the schemas and files in a widget.</li> <li>Input Block - Describes the schemas and files in an input block.</li> <li>Template - Describes the schemas and files in a template.</li> <li>Shared Library - Explains use of AI Verify Shared Library.</li> <li>AI Verify Plugin Tool - How to use the AI Verify Plugin tool.</li> </ul>"},{"location":"plugins/widget/#guides","title":"Guides","text":"<ul> <li>MDX Guide - Overview of MDX and some examples.</li> </ul>"},{"location":"plugins/widget/InputBlock/","title":"Input Block","text":"<p>Each input block consists of at least three files located under the inputs folder, which follows the following naming convention:</p> <ul> <li>\\&lt;input block cid&gt;.meta.json</li> <li>\\&lt;input block cid&gt;.mdx</li> <li>\\&lt;input block cid&gt;.summary.mdx</li> </ul> <p>Assuming you have created a input block with cid \"sample-input-block\", then there should be the following files under the inputs folder:</p> <ul> <li>sample-input-block.meta.json</li> <li>sample-input-block.mdx</li> <li>sample-input-block.summary.mdx</li> </ul>"},{"location":"plugins/widget/InputBlock/#input-block-meta-data","title":"Input Block Meta Data","text":"<p>During installation, the Plugin Manager will search for and validate the input block meta data according to the schema ai-verify.inputBlock.schema.json schema definitions.</p> Propreties Type Required Description cid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique identifier for the input block within the plugin. name string Yes Input block name. description string No Input block description. group string No Input blocks that have the same group name will be grouped together in the user input page width string, enum [\"xs\", \"sm\", \"md\", \"lg\", \"xl\"] No Defines the width of the input block dialog box in the user input page. If not set, the width will default to \"md\" fullScreen boolean No Whether the dialog box in the input block should be in fullscreen mode. If this is set to true, the width property is not used <p>Note: The input block meta data does not contain a gid property as it is automatically inferred and referenced using the format</p> <p>\\&lt;plugin gid&gt;:\\&lt;input block cid&gt;</p>"},{"location":"plugins/widget/InputBlock/#example","title":"Example","text":"<pre><code>{\n  \"cid\": \"sample-input-block\",\n  \"name\": \"Sample Input Block\",\n  \"description\": \"This is a sample input block\",\n  \"group\": \"Sample Group\",\n  \"width\": \"md\",\n  \"fullScreen\": false\n}\n</code></pre>"},{"location":"plugins/widget/InputBlock/#input-block-mdx","title":"Input Block MDX","text":"<p>The input blocks are launched as dialog in the user input page, with the width of the dialog box depending on the width property in the meta data. </p> <p>The MDX are loaded as React components and the component properties are passed and accessed as props global variable. </p>"},{"location":"plugins/widget/InputBlock/#input-block-props","title":"Input Block Props","text":"Propreties Type Description data object Key-Value Object containing the user input data saved onChangeData (key: string, value: any) =&gt; void Function to save user data, e.g. <code>props.onChangeData(\"mykey\",\"Hello World\")</code>"},{"location":"plugins/widget/InputBlock/#input-block-summary","title":"Input Block Summary","text":"<p>For each input block, there should be a summary file \\&lt;input block cid&gt;.summary.mdx that is imported by the AI Verify portal. The script MUST implement and export the following methods. For Example,</p> <pre><code>{/* Return summary of data */}\nexport const summary = (data) =&gt; {\n    // TODO: replace below code with meaningful summary of data.\n  if (!data)\n    return \"No data\";\n  return JSON.stringify(data || {})\n}\n\n{/* Return progress in percentage (0-100) */}\nexport const progress = (data) =&gt; {\n    // TODO: replace below code with percentage of user completion.\n  if (!data)\n    return 0;\n  const totalKeys = 3;\n  const numKeys = Object.values(data).filter(v =&gt; {\n    if (typeof (v) === \"string\" || Array.isArray(v)) {\n      return v.length &gt; 0;\n    } else {\n      return true;\n    }\n  }).length;\n  return Math.round((numKeys / totalKeys) * 100);\n}\n\n{/* Validate data. */}\nexport const validate = (data) =&gt; {\n  // TODO: replace below code with data validation. \n  return progress(data) == 100;\n}\n</code></pre> <p>Developers should implement the methods as defined to provide meaningful summary and track progress of the input block completion. The <code>validate</code> method tells the portal whether the input block data is valid.</p> <p>If the input block summary <code>validate</code> function return false, then the portal will not allow report generation until the input block data validate success. If the input block does not require the data to be validated before generating report, then developer should return true for this function.</p>"},{"location":"plugins/widget/MDX_Guide/","title":"MDX Simple Guide","text":"<p>MDX is a superset of markdown that allows developers to use JDX in the markdown content. It allows developers to write Markdown with embedded components through JSX. You can learn more about MDX in the MDX Site.</p> <p>For AI Verify projects, widgets and input blocks use MDX to create dynamic React components that is loaded as part of canvas or user input prompts.</p>"},{"location":"plugins/widget/MDX_Guide/#mdx-props","title":"MDX Props","text":"<p>MDX props is used to pass data from the parent container to the MDX content. The data is accessed through the global props variable. The following sections describe what data is passed to the widget and input block MDX.</p>"},{"location":"plugins/widget/MDX_Guide/#widget-props","title":"Widget Props","text":"<p>Each widget MDX has the following properties:</p> <ul> <li>props.inputBlockData</li> <li>props.result</li> <li>props.properties</li> <li>props.container</li> </ul> <p>Note: For inputBlockData and result properties, developer should handle cases where the result or input block data is not available and handle accordingly.</p> <p>For example, to access the result of an algorithm.</p> <pre><code>export const algo_gid = \"my-algoritm-gid\"\n\n{props.result[algo_gid]?(\n  &lt;&gt;\n    &lt;b&gt;JSON output of algorithm&lt;/b&gt;\n    &lt;div style={{ maxHeight:\"100px\", overflow:\"auto\" }}&gt;{JSON.stringify(props.result[algo_gid])}&lt;/div&gt;\n  &lt;/&gt;\n):(\n  &lt;div&gt;No data&lt;/div&gt;\n)}\n</code></pre> <p>The following example display the width and height of the parent container.</p> <pre><code>&lt;div style={{ widget:props.container.width, backgroundColor:\"olive\", color:\"white\" }}&gt;\n  Container size: width {props.container.width}px, height {props.container.height}px\n&lt;/div&gt;\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#input-block-props","title":"Input Block Props","text":"<p>Each input block MDX has the following properties:</p> <ul> <li>props.data</li> <li>props.onChangeData</li> </ul>"},{"location":"plugins/widget/MDX_Guide/#markdown","title":"Markdown","text":"<p>MDX supports standard Markdown (see cheatsheet).</p> <p>Some examples of markdown.</p> <p>Italic and bold text with some <code>inline code</code>. * Unordered list 1. Ordered List</p>"},{"location":"plugins/widget/MDX_Guide/#jsx","title":"JSX","text":"<p>JSX provides support for reusable components in MDX.</p> <p>For example, to use JSX markup directly:</p> <pre><code>&lt;div&gt;Hello World&lt;/div&gt;\n</code></pre> <p>To create a JDX component in an MDX:</p> <pre><code>export const HelloWorld = () =&gt; (\n  &lt;div&gt;Hello World again&lt;/div&gt;\n)\n\n&lt;HelloWorld /&gt;\n</code></pre> <p>It is also possible to import another MDX or component file.</p> <p>For example, you can save the above HelloWorld component to a seperate \"helloWorld.mdx\" file and then import it using:</p> <pre><code>import { HelloWorld } from './helloWorld.mdx'\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#html-form-elements-for-input-block","title":"HTML Form Elements for Input Block","text":"<p>Developers can use HTML form elements to prompt and capture user input. Developers can use <code>props.onChangeData</code> to save the user data. Onchange, the saved data will be available in <code>props.data</code>.</p> <p>Below is an example of a component that displays a simple form and save the form data onChange.</p> <pre><code>&lt;div style={{ display:\"flex\", flexDirection:\"column\", marginBottom:\"10px\" }}&gt;\n  &lt;label htmlFor=\"fname\"&gt;First name:&lt;/label&gt;\n  &lt;input type=\"text\" id=\"fname\" value={props.data[\"fname\"]} onChange={(e)=&gt;props.onChangeData(\"fname\",e.target.value)} /&gt;\n  &lt;label htmlFor=\"lname\"&gt;Last name:&lt;/label&gt;\n  &lt;input type=\"text\" id=\"lname\" value={props.data[\"lname\"]} onChange={(e)=&gt;props.onChangeData(\"lname\",e.target.value)} /&gt;\n  &lt;label htmlFor=\"bio\"&gt;Bio:&lt;/label&gt;\n  &lt;textarea rows=\"4\" style={{ width:\"100%\", resize:\"none\" }} value={props.data[\"bio\"]} onChange={(e)=&gt;props.onChangeData(\"bio\",e.target.value)} /&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#ai-verify-shared-library","title":"AI Verify Shared Library","text":"<p>The AI Verify Shared Library provides some shared components that can be imported by MDX. See Shared Library Documentation.</p>"},{"location":"plugins/widget/MDX_Guide/#jsx-component-styling","title":"JSX Component Styling","text":"<p>To ensure consistent stylings for widgets, it is recommended that JSX components use the CSS classes as provided in the AI Verify Shared Library Styles.</p> <p>The following classnames provide different color schemas:</p> <ul> <li>c-primary</li> <li>c-secondary</li> <li>c-success</li> <li>c-info</li> <li>c-warning</li> <li>c-error</li> </ul> <p>For example, to change header color: <pre><code>&lt;h4 class=\"c-primary\"&gt;Primary Test Color&lt;/h4&gt;\n</code></pre></p> <p>To style buttons: <pre><code>&lt;button class=\"aiv-button\"&gt;My Button&lt;/button&gt;\n</code></pre></p> <p>To use a different color for styled buttons: <pre><code>&lt;button class=\"aiv-button c-secondary\"&gt;My Button&lt;/button&gt;\n</code></pre></p>"},{"location":"plugins/widget/MDX_Guide/#example-use-of-barcharts","title":"Example use of BarCharts","text":"<p>Below is an example of how to add a BarChart component from the AI Verify Shared Charts Library.</p> <pre><code>import { BarChart } from 'ai-verify-shared-library/charts'\n\nexport const data01 = [\n  {\n    name: 'Page A',\n    uv: 4000,\n    pv: 2400,\n    amt: 2400,\n  },\n  {\n    name: 'Page B',\n    uv: 3000,\n    pv: 1398,\n    amt: 2210,\n  },\n  {\n    name: 'Page C',\n    uv: 2000,\n    pv: 9800,\n    amt: 2290,\n  },\n  {\n    name: 'Page D',\n    uv: 2780,\n    pv: 3908,\n    amt: 2000,\n  },\n  {\n    name: 'Page E',\n    uv: 1890,\n    pv: 4800,\n    amt: 2181,\n  },\n  {\n    name: 'Page F',\n    uv: 2390,\n    pv: 3800,\n    amt: 2500,\n  },\n  {\n    name: 'Page G',\n    uv: 3490,\n    pv: 4300,\n    amt: 2100,\n  },\n];\n\n&lt;div style={{ width:props.container.width, height:\"220px\", padding:\"10px\" }}&gt;\n  &lt;BarChart\n    data={data01}\n    xAxisDataKey=\"name\"\n    bars={[{ dataKey:\"uv\" }, { dataKey:\"pv\" }, { dataKey:\"amt\" }]}\n  /&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#example-use-of-decision-tree","title":"Example use of Decision Tree","text":"<p>The AI Verify Shared Library DecisionTree allows user to build their own decision tree.</p> <p>You can find an example of Decision Tree Input Block from the Fairness Metrics Toolbox for Classification plugin. An example use of the DecisionTree component can be found in the implementation for the AI Verify Fairness Tree is found under the inputs folder.</p>"},{"location":"plugins/widget/Plugin/","title":"AI Verify Plugin","text":"<p>The AI Verify plugins allows contributors to developer their own plugins, that can be installed into AI Verify portal and used to extend the functionality of the portal.</p>"},{"location":"plugins/widget/Plugin/#terminology","title":"Terminology","text":"<p>This section defines the terminology used.</p> Term Definition plugin AI Verify plugin that can be installed using the AI Verify portal. component Each AI Verify plugin consists of one or more components and can be used to extend the functionality of the system. The types of components are described in the table below. gid Global Identifier. All plugins requires a unique global identifier that is used to identify the plugin. See Global Identifier (GID). cid Component ID. Unique ID that identifies the component within the plugin. See Component Identifier (CID)"},{"location":"plugins/widget/Plugin/#plugin-structure","title":"Plugin Structure","text":"<p>The diagram below describes the folders and files that may be found under each plugin. </p> <p>Each of the component type folder can contain one or more components.</p> <p>For algorithms, each algorithm has its own subfolder under the algorithms folder named with the algorithm id. For example, algorithmA should have a sub-folder called \"algorithmA\" under the algorithms folder.</p> <p>For widgets, input blocks and templates, each instance of the components should be saved under the component folder; and the filenames of the component should correspond to the component cid. For example, widgetA should have the following files under the widgets folder. * widgetA.meta.json * widgetA.mdx</p>"},{"location":"plugins/widget/Plugin/#ai-verify-components","title":"AI Verify Components","text":"<p>The different components that can be found in a plugin is described in the table below. Please refer to the linked article for more information on the component schemas and required files.</p> Component Type Component Type Folder Description Algorithm algorithms Algorithm components add new test algorithms to the system. Input Block inputs Loaded as a dialog box at the project User Input page ot prompt user to input data Widget widgets Used in canvas to display information to user and printed as part of report. Template templates Project templates that, when installed, can be used at creation of new projects to load a pre-defined canvas"},{"location":"plugins/widget/Plugin/#plugin-package","title":"Plugin Package","text":"<p>The plugin package is a zip file containing the plugin meta file (plugin.meta.json) and at least one components type folder containing at least one component. The file and folder structure of a plugin is described in the plugin structure diagram.</p>"},{"location":"plugins/widget/Plugin/#global-identifier-gid","title":"Global Identifier (GID)","text":"<p>The GID identifies the plugin and MUST be globally unique, i.e. no two plugin should have the same GID. The format of the GID must match the following pattern:</p> <p>^a-zA-Z0-9*$</p> <p>Note that the first character of the GID must be an alphanumeric character. It is recommended to use a tool like UUID Version 4 generator to generate the GID.</p>"},{"location":"plugins/widget/Plugin/#component-identifier-cid","title":"Component Identifier (CID)","text":"<p>The CID identifies a plugin component and MUST be unique within the plugin. The format of the GID must match the follow pattern:</p> <p>^a-zA-Z0-9*$</p>"},{"location":"plugins/widget/Plugin/#plugin-meta-data","title":"Plugin Meta Data","text":"<p>The plugin.meta.json file is required for all plugins. During installation, the Plugin Manager will scan the root plugin folder for the file and validates the file according to the ai-verify.plugin.schema.json schema definition.</p> Propreties Type Required Description gid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique global identifier to identify the plugin. version string Yes Plugin version, should follow Semantic Versioning format. name string Yes Plugin name author string No Author of the plugin description string No Description of the plugin url string No URL to the plugin web page if available"},{"location":"plugins/widget/Plugin/#example","title":"Example","text":"<pre><code>{\n  \"gid\": \"e6402035-7294-4b69-ace1-68a0442f0194\",\n  \"name\": \"Sample Plugin\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Acme Corporation\",\n  \"description\": \"This is a sample plugin\",\n  \"url\": \"https://acme.com/sampleplugin/\"\n}\n</code></pre>"},{"location":"plugins/widget/Plugin_Tool/","title":"AI Verify Plugin Tool","text":"<p>The ai-verify-plugin tool is a command-line tool that help widget and input block developers to develop and scaffold AI Verify plugin projects directly from command line. </p>"},{"location":"plugins/widget/Plugin_Tool/#installation","title":"Installation","text":"<p>To install the tool, clone the aiverify-developer-tools repo. The plugin tools is also dependent on the shared library in the aiverify repository.</p> <p>To clone the repository, run the following commands. <pre><code>git clone git@github.com:IMDA-BTG/aiverify-developer-tools.git\n</code></pre></p> <p>Assuming the aiverify repository and the aiverify-developer-tools is under the same parent folder, install the plugin tool and link the shared library with the following command.</p> <pre><code>cd aiverify-developer-tools/ai-verify-plugin\nnpm install\nnpm link ../../aiverify/ai-verify-shared-library/\nnpm install -g\n</code></pre>"},{"location":"plugins/widget/Plugin_Tool/#basic-use","title":"Basic Use","text":"<p>Once the tool is installed, it can be invoked with <code>ai-verify-plugin</code>. The command line syntax is as follows:</p> <pre><code>ai-verify-plugin &lt;cmd&gt; [args]\n</code></pre> <p>The second argument  is the command to run. The <code>--help</code> argument will output the help menu for the tool or the command. For example, <pre><code>ai-verify-plugin --help\nai-verify-plugin generate-plugin --help\n</code></pre>"},{"location":"plugins/widget/Plugin_Tool/#commands","title":"Commands","text":"<p>You can view the list of commands with <code>ai-verify-plugin --help</code>.</p> <pre><code>ai-verify-plugin &lt;cmd&gt; [args]\n\nCommands:\n  ai-verify-plugin generate-plugin [gid]      Generate skeleton AI Verify plugin project                   [aliases: gp]\n  ai-verify-plugin generate-widget &lt;cid&gt;      Generate skeleton AI Verify widget                           [aliases: gw]\n  ai-verify-plugin generate-inputblock &lt;cid&gt;  Generate skeleton AI Verify input block                     [aliases: gib]\n  ai-verify-plugin zip [pluginDir]            Create the plugin zip file\n  ai-verify-plugin validate                   Validate AI Verify plugin\n  ai-verify-plugin test                       Run the plugin tests\n  ai-verify-plugin playground                 Launch the plugin playround\n\nOptions:\n  --help  Show help                                                                                            [boolean]\n</code></pre> <p>Tip: Using the gp, gw and gib commands on existing plugin or component will update the component meta data with any new arguments specified. To overwrite existing meta properties, use the --force argument.</p>"},{"location":"plugins/widget/Plugin_Tool/#generate-plugin-alias-gp","title":"generate-plugin [alias: gp]","text":"<p>This command generates a skeleton plugin project.</p> <pre><code>ai-verify-plugin generate-plugin [gid]\n\nGenerate skeleton AI Verify plugin project\n\nPositionals:\n  gid  Plugin Global ID                           [string] [default: If not specified, a random UUID will be generated.]\n\nOptions:\n  --help         Show help                                                                                     [boolean]\n  --name         Plugin name. If not provided will be set to same as gid.                                       [string]\n  --version      Plugin version. Version should be a valid semantic version.                 [string] [default: \"1.0.0\"]\n  --author       Plugin author                                                                                  [string]\n  --description  Plugin description                                                                             [string]\n  --url          Plugin URL                                                                                     [string]\n  --force        Overwrite existing settings. By default existing settings will not be overwritten.            [boolean]\n</code></pre> <p>If the command run is successful, the tool will generate a folder with the same name as the plugin gid and the following files:</p> File Description plugin.meta.json Contains the plugin meta information README.md Contains generic README for the plugin .gitignore List of untracked files for git to ignore"},{"location":"plugins/widget/Plugin_Tool/#examples","title":"Examples","text":"<p>To generate plugin with random gid. <pre><code>ai-verify-plugin gp --name \"My Plugin\" --description \"Just a test plugin\"\n</code></pre></p> <p>To generate plugin with specific gid. <pre><code>ai-verify-plugin gp \"myplugin\" --name \"My Plugin\" --description \"Just a test plugin\"\n</code></pre></p>"},{"location":"plugins/widget/Plugin_Tool/#generate-widget-alias-gw","title":"generate-widget [alias: gw]","text":"<p>To generate a widget, cd to a plugin project folder and run the following command.</p> <pre><code>ai-verify-plugin generate-widget &lt;cid&gt;\n\nGenerate skeleton AI Verify widget\n\nPositionals:\n  cid  Widget Component ID                                                                           [string] [required]\n\nWidget Sizes\n  --minW  Specify the minimum widget width (1-12)                                                  [number] [default: 1]\n  --minH  Specify the minimum widget height (1-36)                                                 [number] [default: 1]\n  --maxW  Specify the maximum widget width (1-12)                                                 [number] [default: 12]\n  --maxH  Specify the maximum widget height (1-36)                                                [number] [default: 36]\n\nOptions:\n  --help               Show help                                                                               [boolean]\n  --name               Widget name. If not provided will be set to same as cid.                                 [string]\n  --description        Widget description                                                                       [string]\n  --tag                Allow users to search and filter by tags                                                  [array]\n  --dep, --dependency  Option format: \"&lt;Algorithm|InputBlock&gt;,gid[,version]\". Add the option as dependency in the widget\n                       meta config.                                                                              [array]\n  --prop, --property   Option format: \"key[,helper][,default]\". Add the option as property in the widget meta config.\n                                                                                                                 [array]\n  --force              Overwrite existing settings. By default existing settings will not be overwritten.      [boolean]\n  --pluginDir          Path to plugin directory                                                  [string] [default: \".\"]\n</code></pre> <p>Notes: * For every dependencies defined, a sample json file \"\\&lt;gid&gt;.sample.json\" will be created.</p> <p>Upon successful command run, the following files are generated under the widgets sub-folder:</p> File Description \\&lt;widget cid&gt;.meta.json Contains the widget meta information \\&lt;widget cid&gt;.mdx MDX script for the widget \\&lt;dep gid&gt;.sample.json JSON file containing sample data for each dependency specified"},{"location":"plugins/widget/Plugin_Tool/#examples_1","title":"Examples","text":"<p>Generate a widget without any dependencies and properties. <pre><code>ai-verify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget without dependencies and properties\"\n</code></pre></p> <p>Generate a widget with a couple of tags. <pre><code>ai-verify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with tags\" --tag mytag1 --tag mytag2\n</code></pre></p> <p>Generate a widget with minimum width set to 12. <pre><code>ai-verify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with minW 12\" --minW 12\n</code></pre></p> <p>Generate a widget with properties. <pre><code>ai-verify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with properties\" --prop \"title,Title text to display,Hello World\"\n</code></pre></p> <p>Generate a widget with dependencies. <pre><code>ai-verify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with dependencies\" --dep \"Algorithm,my-fake-algo-gid,1.1.0\" --dep \"InputBlock,my-input-block\"\n</code></pre></p>"},{"location":"plugins/widget/Plugin_Tool/#generate-inputblock-alias-gib","title":"generate-inputblock [alias: gib]","text":"<p>To generate an input block, cd to a plugin project folder and run the following command.</p> <p><pre><code>ai-verify-plugin generate-inputblock &lt;cid&gt;\n\nGenerate skeleton AI Verify input block\n\nPositionals:\n  cid  Input Block Component ID                                                                      [string] [required]\n\nOptions:\n  --help         Show help                                                                                     [boolean]\n  --name         Input Block name. If not provided will be set to same as cid.                                  [string]\n  --description  Input Block description                                                                        [string]\n  --group        Input Block group. Input blocks of the same group name (case-senstive) will be grouped together in the\n                 input block list                                                                               [string]\n  --width        Width of input block dialog box                        [string] [choices: \"xs\", \"sm\", \"md\", \"lg\", \"xl\"]\n  --fullScreen   Whether the input block dialog should be full screen                                          [boolean]\n  --force        Overwrite existing files or settings. By default existing files and settings will not be overwritten.\n                                                                                                               [boolean]\n  --pluginDir    Path to plugin directory                                                        [string] [default: \".\"]\n</code></pre> Upon successful command run, the following files are generated under the inputs sub-folder:</p> File Description \\&lt;input block cid&gt;.meta.json Contains the input block meta information \\&lt;input block cid&gt;.mdx MDX script for the input block \\&lt;input block cid&gt;.ts Typescript containing the input block summary methods"},{"location":"plugins/widget/Plugin_Tool/#examples_2","title":"Examples","text":"<p>Generate with input block. <pre><code>ai-verify-plugin gib \"myinputblock\" --name \"My Input Block\" --description \"An input block\"\n</code></pre></p> <p>Generate with input block with dialog width \"lg\" <pre><code>ai-verify-plugin gib \"myinputblock\" --name \"My Input Block\" --description \"An input block with dialog width lg\" --width lg\n</code></pre></p>"},{"location":"plugins/widget/Plugin_Tool/#zip","title":"zip","text":"<p>This commands create a plugin zip file that can be uploaded to the AI Verify portal using the Plugin Manager.</p> <pre><code>ai-verify-plugin zip [pluginDir]\n\nCreate the plugin zip file\n\nPositionals:\n  pluginDir  Path to plugin directory                                                            [string] [default: \".\"]\n\nOptions:\n  --help             Show help                                                                                 [boolean]\n  --skip-validation  Skip validation                                                                           [boolean]\n</code></pre> <p>Notes * By default, the zip command will run validation tests first before creating the plugin zip. The \"--skip-validation\" option allows user to skip the validation step.</p>"},{"location":"plugins/widget/Plugin_Tool/#validate","title":"validate","text":"<p>This command run validate checks on the meta files and MDX scripts under the plugin folder.</p> <pre><code>ai-verify-plugin validate\n\nValidate AI Verify plugin\n\nOptions:\n  --help       Show help                                                                                       [boolean]\n  --pluginDir  Path to plugin directory                                                          [string] [default: \".\"]\n</code></pre>"},{"location":"plugins/widget/Plugin_Tool/#test","title":"test","text":"<p>This command uses Jest to run tests on the plugin files and scripts.</p> <pre><code>ai-verify-plugin test\n\nRun the plugin tests\n\nOptions:\n      --help                         Show help                                                                                [boolean]\n      --pluginDir                    Path to plugin directory                                                   [string] [default: \".\"]\n      --coverage, --collectCoverage  Indicates that test coverage information should be collected and reported in the output.\n                                                                                                             [boolean] [default: false]\n      --listTests                    Lists all test files that Jest will run given the arguments, and exits. [boolean] [default: false]\n      --showConfig                   Print your Jest config and then exits.                                  [boolean] [default: false]\n      --watch                        Watch files for changes and rerun tests related to changed files.       [boolean] [default: false]\n      --watchAll                     Watch files for changes and rerun all tests when something changes.     [boolean] [default: false]\n      --ci                           When this option is provided, Jest will assume it is running in a CI environment.\n                                                                                                             [boolean] [default: false]\n  -u, --updateSnapshot               Use this flag to re-record every snapshot that fails during this test run.\n                                                                                                             [boolean] [default: false]\n      --json                         Prints the test results in JSON. This mode will send all other test output and user messages to\n                                     stderr.                                                                 [boolean] [default: false]\n      --outputFile                   Write test results to a file when the --json option is also specified.                    [string]\n</code></pre> <p>By default, the command will run validation and snapshot tests on the input blocks and widgets found under the plugin directory. The snapshots will be saved to <code>__snapshots__</code> folder under the plugin directory. It is recommended that developers add the <code>__snapshots__</code> folder to their project repository. </p> <p>To add additional Jest tests, developers can write their own tests and place them under <code>__tests__</code> folder under the plugin directory.</p>"},{"location":"plugins/widget/Plugin_Tool/#playground","title":"playground","text":"<p>This command launches a web playground app to allow developers to view widgets and input blocks during development.</p> <pre><code>ai-verify-plugin playground\n\nLaunch the plugin playround\n\nOptions:\n  --help       Show help                                                                                       [boolean]\n  --pluginDir  Path to plugin directory                                                          [string] [default: \".\"]\n  --port       Playground port to listen on                                                     [number] [default: 5000]\n  --hostname   Playground hostname to listen on                                          [string] [default: \"localhost\"]\n</code></pre> <p>To start the playground, runs the playground command under a plugin directory. The command will scan for the algorithms, widgets and input blocks found under the plugin and luanches the playground app listening on http://localhost:5000/ by default. To change the port and hostname, use the options to configure.</p>"},{"location":"plugins/widget/Shared_Library/","title":"AI Verify Frontend Shared Library","text":""},{"location":"plugins/widget/Shared_Library/#shared-library","title":"Shared Library","text":""},{"location":"plugins/widget/Shared_Library/#ai-verify-shared-library","title":"AI Verify Shared Library","text":"<p>The shared library is found under the <code>ai-verify-shared-library</code> folder under the aiverify repository.</p> <p>The Shared Library contains various shared components that can be used by widget developers in the MDX code. </p> <p>The library contains the following packages:</p> <ul> <li>Styles</li> <li>Charts</li> <li>Graph</li> </ul> <p>Further information on the shared components in the packages and their usage can be found in the README of the package.</p>"},{"location":"plugins/widget/Template/","title":"Template","text":"<p>Each input block consists of at least two files located under the templates folder, which follows the following naming convention:</p> <ul> <li>\\&lt;template cid&gt;.meta.json</li> <li>\\&lt;template cid&gt;.data.mdx</li> </ul>"},{"location":"plugins/widget/Template/#template-meta-data","title":"Template Meta Data","text":"<p>During installation, the Plugin Manager will search for and validate the input block meta data according to the schema ai-verify.template.schema.json schema definitions.</p> Propreties Type Required Description cid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique identifier for the template within the plugin. name string Yes Template name. description string No Template description. author string No Template author"},{"location":"plugins/widget/Template/#exporting-a-template-plugin","title":"Exporting a Template Plugin","text":"<p>For now, the easiest way to create a template component is to export the template as plugin at the AI Verify Project page. This will download a zip file that contains a plugin containing the template data. To add the template component to an existing plugin project, simply copy the templates folder in the plugin zip to the target plugin folder. </p>"},{"location":"plugins/widget/Widget/","title":"Widget","text":"<p>Each widget consists of at least two files, a meta file describing the widget and the MDX file for the widget. The files should be located under widgets folder of the plugin root directory, and file names should follow this format:</p> <ul> <li>\\&lt;widget cid&gt;.meta.json</li> <li>\\&lt;widget cid&gt;.mdx</li> </ul> <p>Assuming you have created a widget with cid \"sample-widget\", then there should be the following files under the widgets folder:</p> <ul> <li>sample-widget.meta.json</li> <li>sample-widget.mdx</li> </ul>"},{"location":"plugins/widget/Widget/#widget-meta-data","title":"Widget Meta Data","text":"<p>During installation, the Plugin Manager will search for and validate the widget meta data according to the schema ai-verify.widget.schema.json schema definitions.</p> Propreties Type Required Description cid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique identifier for the widget within the plugin. name string Yes Widget name. description string No Widget description. widgetSize object Yes Describe the widget size in terms of canvas grid units. See Widget Size Object Schema for the schema of the widgetSize object. properties array No List of widget properties. See Widget Property Schema. tags array of string No List of tags for this widget. Used for search and filtering of the widget dependencies array No List of input blocks and/or algorithms that this widget depends on. See Widget Dependency Schema. mockdata array No List of sample data that is provided to the widget in the canvas page. See Widget Mock Data Schema. dynamicHeight boolean No Indicates whether this widget has dynamic height. See Dynamic Height Widget <p>Note: The widget meta data does not contain a gid property as it is automatically inferred and referenced using the format</p> <p>\\&lt;plugin gid&gt;:\\&lt;widget cid&gt;</p>"},{"location":"plugins/widget/Widget/#dynamic-height-widget","title":"Dynamic Height Widget","text":"<p>When the widget's <code>dynamicHeight</code> meta property is set to true, it indicates that the widget has dynamic height. Dynamic height widgets are special widgets that are treated different at the portal:</p> <ul> <li>At the canvas editor page, dynamic height widgets must be placed at the bottom most position on the canvas, meaning there can be no other widgets beneath a dynamic height widget.</li> <li>During report generation, the widget can \"overflow\" beyond the current page. The report generator will automatically insert page breaks.</li> </ul> <p>Dynamic height widget can use CSS <code>break-after</code>, <code>break-before</code> and <code>break-inside</code> properties to specify where the page breaks can or cannot occur.</p>"},{"location":"plugins/widget/Widget/#widget-size-object-schema","title":"Widget Size Object Schema","text":"<p>The widgetSize property defines the minimum and maximum size of the widget. It is defined in the grid units that is used for the project canvas. When the template designer drags a widget onto the canvas, the default size of the widget is the minimum width and height defined.</p> Propreties Type Required Description minW interger, range 1-12 Yes Minimum widget width. minH interger, range 1-36 Yes Minimum widget height. maxW interger, range 1-12 Yes Maximum widget width. maxH interger, range 1-36 Yes Maximum widget height."},{"location":"plugins/widget/Widget/#widget-property-schema","title":"Widget Property Schema","text":"<p>The widget properties allows widget developers to define properties that affects the look and/or behaviour of the widget. Example of properties are color, textual information, etc. Each property should have a default value that is used if the property has no input. The template designers can change the properties of a widget by right clicking the widget in the canvas page to bring up the property dialog. Each property value can be a string input or selected from the canvas Global Properties.</p> Propreties Type Required Description key string Yes Property key. helper string Yes Helper text for the property. default string No Default value for the property."},{"location":"plugins/widget/Widget/#widget-dependency-schema","title":"Widget Dependency Schema","text":"<p>Widget dependencies define the list of input blocks or algorithms that the widget depends on.</p> Propreties Type Required Description cid string Yes CID of the component dependency. gid string No GID of the plugin which the component dependency resides in. Not required if the component dependency resides in the same plugin as this widget version string No Version of the component dependency. If version is not specified, then no version check will be performed <p>The version property is optional. If no version is specified, then the portal dependency check will NOT do version checking. It is recommended to specify the dependency version if referencing a component in other plugins.</p> <p>If the widget defines an input block dependency, the data that user entered in the AI Verify Portal's User Input page can be accessed from the widget MDX through MDX props <code>props.getIBData</code> method.</p> <p>If the widget defines an algorithm dependency, the results that is output by the algorithm will be provided to the widget MDX as MDX props <code>props.getResults</code> method.</p>"},{"location":"plugins/widget/Widget/#widget-mock-data-schema","title":"Widget Mock Data Schema","text":"<p>Widget mock data provides mock data to the widget at the canvas page. If no mock data is provided, then no data will be provided to the widget at canvas page and the widget MDX should handle this condition.</p> Propreties Type Required Description type string, enum [\"Algorithm\", \"InputBlock\"] Yes Type of sample data cid string Yes CID of the component dependency gid string No GID of the plugin which the component dependency resides in. Not required if the component dependency resides in the same plugin as this widget datapath string yes File path containing the mock data in JSON format, e.g. mockdata.json. The file should be located within the widgets folder."},{"location":"plugins/widget/Widget/#example","title":"Example","text":"<pre><code>{\n  \"cid\": \"sample-widget\",\n  \"name\": \"Sample Widget\",\n  \"description\": \"This is a sample widget\",\n  \"tags\": [\"sample\"],\n  \"properties\": [\n    {\n      \"key\": \"title\",\n      \"helper\": \"Enter the widget title to be displayed at the top of the widget\",\n      \"default\": \"\"\n    }\n  ],\n  \"widgetSize\": {\n    \"minW\": 1,\n    \"minH\": 1,\n    \"maxW\": 12,\n    \"maxH\": 36\n  },\n  \"dependencies\": [\n    {\n      \"cid\": \"fairness_metrics_toolbox_for_classification\",\n    },\n    {\n      \"cid\": \"fairness_tree\"\n    }\n  ],\n  \"mockdata\": [\n    {\n      \"type\": \"Algorithm\",\n      \"cid\": \"fairness_metrics_toolbox_for_classification\",\n      \"datapath\": \"fmt.output.sample.json\" \n    },\n    {\n      \"type\": \"InputBlock\",\n      \"cid\": \"fairness_tree\",\n      \"datapath\": \"fairness_tree.sample.json\"\n    }\n  ]\n}\n</code></pre>"},{"location":"plugins/widget/Widget/#widget-mdx","title":"Widget MDX","text":"<p>Each widget must contain a valid MDX that will be rendered as a widget in an AI Verify report. During creation or update of an AI Verify project, the user can drag and drop a widget onto a project canvas, which will be eventually rendered as part of a report.</p> <p>The widget dependencies informs the sytem what are the algorithms and/or input blocks that the widget depends on. The system then determine what are the algorithms and input blocks to run based on the dependency info. </p> <p>The widget MDX are loaded as React components and the component properties are passed and accessed as props global variable. </p>"},{"location":"plugins/widget/Widget/#widget-props","title":"Widget Props","text":"Propreties Type Description inputBlockData object Object containing the user input data saved, accessed by its gid <code>props.inputBlockData[gid]</code>. result object Object containing the output from an algorithm, accessed by its gid <code>props.result[gid]</code>. properties object Object containing the widget properties entered in the canvas page. container object Object containing the widget container information, see Widget Container getContainerObserver(callback) function Function to create an observer to retrieve the the widget container size, see Widget Container Observer getResults(cid, gid=null) function Function to return result of an algorithm identified by cid. If gid of the algorithm is not specified, the function assumes same plugin gid as the widget. getIBData(cid, gid=null) function Function to return data of an input block identified by cid. If gid of the input block is not specified, the function assumes same plugin gid as the widget. getTest(cid, gid=null) function Function to return test result information (if successful), see Test Result Information meta object Object containing widget meta data. report object Object containing report information, see Report modelAndDatasets object Object containing model and dataset information used to run the test (See Models and Datasets) <p>Example MDX to print out some of the widget props: <pre><code>export const cid = \"some_algo_cid\"\n\n&lt;div&gt;\n  &lt;pre&gt;{JSON.stringify(props.modelAndDatasets,null,2)}&lt;/pre&gt;\n  &lt;pre&gt;{JSON.stringify(props.report,null,2)}&lt;/pre&gt;\n  &lt;pre&gt;{JSON.stringify(props.getTest(cid),null,2)}&lt;/pre&gt;\n  &lt;pre&gt;{JSON.stringify(props.getResults(cid),null,2)}&lt;/pre&gt;\n&lt;/div&gt;\n</code></pre></p>"},{"location":"plugins/widget/Widget/#widget-container-observer","title":"Widget Container Observer","text":"<p>To retrieve the size of the widget container, call the following getContainerObserver function. The callback function passes the container width and height in pixel.</p> <pre><code>props.getContainerObserver((width, height) =&gt; {\n  // Do something with the constainer width and height\n})\n</code></pre>"},{"location":"plugins/widget/Widget/#test-result-information","title":"Test Result Information","text":"Propreties Type Description timeStart string ISO data string of start time of test run timeTaken number Time to complete test in seconds testArguments object Test arguments"},{"location":"plugins/widget/Widget/#report","title":"Report","text":"Propreties Type Description timeStart date Date and time of when the report starts generation. timeTaken number Total time taken (in seconds) to run all the tests and generate report. totalTestTimeTaken number Total time taken (in seconds) to run all the tests."},{"location":"plugins/widget/Widget/#models-and-datasets","title":"Models and Datasets","text":"Propreties Type Description testDataset object Object containing test dataset information, see Dataset Object Schema for information on dataset fields model object Object containing model information groundTruthDataset object Object containing ground truth dataset information, see Dataset Object Schema for information on dataset fields groundTruthColumn string Ground truth feature name"},{"location":"plugins/widget/Widget/#dataset-object-schema","title":"Dataset Object Schema","text":"Propreties Type Description filename string File name of dataset name string Name of dataset size string Size of dataset description string Dataset description type string Dataset type (File, Folder) dataFormat string Dataset data format"},{"location":"plugins/widget/Widget/#ai-model-object-schema","title":"AI Model Object Schema","text":"Propreties Type Description name string Name of model description string model description size string Size of model type string Model access type (File, Folder, Pipeline, API) modelType string Model type (Classification, Regression) modelFormat string Model format"},{"location":"stock_plugins/","title":"AI Verify Stock Plugins","text":""},{"location":"stock_plugins/#description","title":"Description","text":"<p>This section documents the various stock plugins packaged in AI Verify.</p>"},{"location":"stock_plugins/#list-of-stock-plugins-in-ai-verify","title":"List of Stock Plugins in AI Verify","text":"<ol> <li>Fairness Metrics Toolbox for Classification</li> <li>Fairness Metrics Toolbox for Regression</li> <li>Robustness Toolbox</li> <li>SHAP</li> <li>Partial Dependent Plot</li> <li>Accumulated Local Effect</li> <li>Image Corruption Algorithms</li> <li>Stock Reports</li> <li>Process Checklist</li> <li>Decorators</li> </ol>"},{"location":"stock_plugins/ale/","title":"Accumulated Local Effect","text":"<p>(aiverify.stock.accumulated-local-effect) [source]</p>"},{"location":"stock_plugins/ale/#description","title":"Description","text":"<p>This plugin explains how each feature and its feature value contribute to the predictions. The results are visualised as line graphs for each feature.</p>"},{"location":"stock_plugins/ale/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Accumulated Local Effect This algorithm explains how each feature and its feature value contribute to the predictions. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to Accumulated Local Effect ALE Line Graphs To generate and display ALE values in line graphs for each feature in each class output Recommendation To provide recommendations on explainability"},{"location":"stock_plugins/ale/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/ale/#data-preparation","title":"Data Preparation","text":"<ul> <li>Tabular dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/ale/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/ale/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"properties\": {\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_names\",\n\"results\"\n],\n\"minProperties\": 1,\n\"properties\": {\n\"feature_names\": {\n\"type\": \"array\",\n\"description\": \"Array of feature names\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"string\"\n}\n},\n\"results\": {\n\"title\": \"Matrix of feature values (# feature names)\",\n\"description\": \"The results of feature names\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"description\": \"Results of indices, ale, and size\",\n\"type\": \"object\",\n\"required\": [\n\"indices\",\n\"ale\",\n\"size\"\n],\n\"minProperties\": 3,\n\"properties\": {\n\"indices\": {\n\"title\": \"Indices\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n},\n\"ale\": {\n\"title\": \"ale (# of indices)\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n},\n\"size\": {\n\"title\": \"size (# of indices)\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/decorators/","title":"AI Verify Stock Decorators","text":"<p>(aiverify.stock.decorators) [source]</p>"},{"location":"stock_plugins/decorators/#description","title":"Description","text":"<p>This plugin contains the stock decorators for the AI Verify report.</p>"},{"location":"stock_plugins/decorators/#plugin-content","title":"Plugin Content","text":"<p>Widgets</p> <ul> <li>Divider</li> <li>Header 1</li> <li>Header 2</li> <li>Header 3</li> <li>Header 4</li> <li>Header 5</li> <li>Header 6</li> </ul>"},{"location":"stock_plugins/fmtc/","title":"Fairness Metrics Toolbox for Classification","text":"<p>(aiverify.stock.fairness-metrics-toolbox-for-classification) [source]</p>"},{"location":"stock_plugins/fmtc/#description","title":"Description","text":"<p>The Fairness Metrics Toolbox (FMT) for Classification contains a list of fairness metrics to measure how resources (e.g. opportunities, food, loan, medical help) are allocated among the demographic groups (e.g. married male, married female) given a set of sensitive feature(s) (e.g. gender, marital status). This plugin is developed for classification models.</p>"},{"location":"stock_plugins/fmtc/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Fairness Metrics Toolbox for Classification This algorithm computes a list of fairness metrics to measure how correctly your model predicts among the given set of sensitive features.  Fairness metrics include: False Negative Rate Parity, False Positive Rate Parity, False Discovery Rate Parity, False Omission Rate Parity, True Positive Rate Parity, True Negative Rate Parity, Positive Predictive Value Parity, Negative Predictive Value Parity <ul> <li>Widgets</li> </ul> Name Description Bar Chart (Selected) To generate bar chart(s) for the selected fairness metric(s) from the fairness tree Interpretation (Selected) To provide interpretation for the selected fairness metric(s) from the fairness tree Description (Summary) To provide an introduction to the Fairness Metrics Toolbox for Classification Interpretation (Summary) To provide interpretation and recommendations to the results Table of Definition To provide a table of definitions for all the fairness metrics calculated Fairness Metrics (All) To generate all fairness metrics"},{"location":"stock_plugins/fmtc/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/fmtc/#data-preparation","title":"Data Preparation","text":"<ul> <li>Tabular dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/fmtc/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Sensitive Feature Name Array of sensitive features names  You may select multiple sensitive features of interest, and as a guide these are usually demographic features <code>array</code>"},{"location":"stock_plugins/fmtc/#algorithm-input-block-fairness-tree","title":"Algorithm Input Block - Fairness Tree","text":"<p>The Fairness Tree helps you to select the most relevant fairness metrics for your use case. Read more on how to use the fairness tree here </p>"},{"location":"stock_plugins/fmtc/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/fmtc/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"title\": \"Sensitive Feature Names\",\n\"description\": \"Array of Sensitive Feature Names (e.g. Gender)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"string\"\n},\n\"minItems\": 1\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\",\n\"output_classes\",\n\"results\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"description\": \"Array of sensitive feature names\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"string\"\n}\n},\n\"output_classes\": {\n\"description\": \"Array of output classes\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": [\n\"string\",\n\"number\",\n\"integer\",\n\"boolean\"\n]\n}\n},\n\"results\": {\n\"description\": \"Array of metrics by output classes (# output classes)\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"object\",\n\"description\": \"Dictionary of metric values by group\",\n\"required\": [\n\"True Positive Rate\",\n\"True Negative Rate\",\n\"Positive Predictive Value Parity\",\n\"Negative Predictive Value Parity\",\n\"False Positive Rate\",\n\"False Negative Rate\",\n\"False Discovery Rate\",\n\"False Omission Rate\",\n\"Equal Selection Parity\",\n\"Disparate Impact\"\n],\n\"properties\": {\n\"True Positive Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"True Negative Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"Positive Predictive Value Parity\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"Negative Predictive Value Parity\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Positive Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Negative Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Discovery Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Omission Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"Equal Selection Parity\": {\n\"$ref\": \"#/$defs/metric2\"\n},\n\"Disparate Impact\": {\n\"$ref\": \"#/$defs/metric2\"\n}\n}\n}\n}\n},\n\"$defs\": {\n\"metric\": {\n\"description\": \"Array of metric values for each group, e.g. [{group:[1,2], metric:0.122},...]\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\n\"group\",\n\"metric\"\n],\n\"properties\": {\n\"group\": {\n\"type\": \"array\",\n\"description\": \"Array of group values, one value for each feature, .e.g group: [1,4,7]\"\n},\n\"metric\": {\n\"type\": \"number\"\n}\n}\n},\n\"minItems\": 2\n},\n\"metric2\": {\n\"description\": \"Array of metric values for each group, e.g. [{group:[1,2], metric:0.122},...]\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\n\"group\",\n\"metric\"\n],\n\"properties\": {\n\"group\": {\n\"type\": \"array\",\n\"description\": \"Array of group values, one value for each feature, .e.g group: [1,4,7]\"\n},\n\"metric\": {\n\"type\": \"number\"\n}\n}\n},\n\"minItems\": 1\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/fmtr/","title":"Fairness Metrics Toolbox for Regression","text":"<p>(aiverify.stock.fairness-metrics-toolbox-for-regression) [source]</p>"},{"location":"stock_plugins/fmtr/#description","title":"Description","text":"<p>This plugin computes and displays a list of fairness metrics to measure how correctly your regression model predicts among the given set of sensitive features.</p>"},{"location":"stock_plugins/fmtr/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Fairness Metrics Toolbox for Regression The algorithm computes a list of fairness metrics to measure how correct your model predicts among the given set of sensitive features. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to the Fairness Metric Toolbox for Regression Understanding Bar Chart To guide your users on reading the generated bar chart Bar Chart (MAE) To generate the bar chart to show the mean absolute error parity between the subgroups Bar Chart (MSE) To generate the bar chart to show the mean square error parity between the subgroups Bar Chart (R2) To generate the bar chart to show the r2 score parity between the subgroups Interpretation (MAE) To interpret the mean absolute error parity results Interpretation (MSE) To interpret the mean square error parity results Interpretation (R2) To interpret the r2 score parity results Recommendation To provide a recommendation for fairness testing for regression models Table of Definitions To provide a table of definitions"},{"location":"stock_plugins/fmtr/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/fmtr/#data-preparation","title":"Data Preparation","text":"<ul> <li>Tabular dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/fmtr/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Sensitive Feature Name Array of sensitive features names  You may select multiple sensitive features of interest, and as a guide these are usually demographic features <code>array</code>"},{"location":"stock_plugins/fmtr/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/fmtr/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"title\": \"Sensitive Feature Names\",\n\"description\": \"Array of Sensitive Feature Names (e.g. Gender)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"string\"\n},\n\"minItems\": 1\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"results\": {\n\"type\": \"array\",\n\"minItems\": 1,\n\"title\": \"The results Schema\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"mae\": {\n\"type\": \"number\"\n},\n\"r2\": {\n\"type\": [\n\"number\",\n\"null\"\n]\n},\n\"mse\": {\n\"type\": \"number\"\n},\n\"subgroup\": {\n\"type\": \"string\"\n}\n}\n}\n}, \"sensitive_feature\":{\n\"description\":\"Array of sensitive feature names\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"string\"\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/image_corruption/","title":"Image Corruption Toolbox","text":"<p>(aiverify.stock.image-corruption-toolbox) [source]</p>"},{"location":"stock_plugins/image_corruption/#description","title":"Description","text":"<p>This plugin tests the robustness of AI models to natural corruptions. </p> <p>There are four different broad groups of corruptions that are packaged in this plugin. Each of these broad groups of corruptions also have more specific corruption functions indicated in brackets below: - General (Gaussian, Poisson, Salt and Pepper Noise) - Blur (Defocus, Gaussian, Glass, Horizontal Motion, Vertical Motion, Zoom Blur) - Digital (Brightness Up and Down, Contrast Up and Down, Compression, Random Tilt, Saturate) - Environmental (Rain, Fog, Snow)</p> <p>The toolbox generates corrupted images based on the uploaded test data at 5 different severity levels for each corruption function. The accuracy of the model is calculated with the new corrupted datasets.</p>"},{"location":"stock_plugins/image_corruption/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Blur Corruptions Algorithm that adds blur corruptions (defocus, gaussian, glass, horizontal motion, vertical motion and zoom Blur) to images at 5 severity levels, and calculates the accuracy of the model Digital Corruptions Algorithm that adds digital corruptions (brightness up and down, contrast up and down, compression, random tilt, saturate) to images at 5 severity levels, and calculates the accuracy of the model Environment Corruptions Algorithm that adds environmental corruptions (rain, fog and snow) to images at 5 severity levels, and calculates the accuracy of the model General Corruptions Algorithm that adds environmental corruptions (gaussian, poisson and salt and pepper noise) to images at 5 severity levels, and calculates the accuracy of the model <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to the Image Corruption Toolbox Understanding Line Chart To guide your users on reading the generated line charts Line Chart (Blur Corruptions) To generate line chart to visualise the accuracy results when blur corruptions are applied <ul> <li> Samples (Blur: Defocus Blur) </li> <li>Samples (Blur: Gaussian Blur) </li> <li>Samples (Blur: Glass Blur) </li> <li> Samples (Blur: Horizontal Motion Blur) </li> <li>Samples (Blur: Vertical Motion Blur) </li> <li>Samples (Blur: Zoom Blur)</li> </ul> To generate sample images for the blur corruptions Line Chart (Digital Corruptions) To generate line chart to visualise the accuracy results when digital corruptions are applied <ul> <li> Samples (Digital:  Brightness Up) </li> <li>Samples (Digital:  Brightness Down) </li> <li>Samples (Digital:  Contrast Up) </li> <li> Samples (Digital:  Contrast Down) </li> <li>Samples (Digital:  Saturate) </li> <li>Samples (Digital: Compression)</li> <li>Samples (Digital: Compression)</li></ul> To generate sample images for the digital corruptions Line Chart (Environmental Corruptions) To generate line chart to visualise the accuracy results when environment corruptions are applied <ul><li> Samples (Environment: Rain) </li><li> Samples (Environment: Fog)</li> <li> Samples (Environment: Snow)</li></ul> To generate samples for the environment corruptions Line Chart (General Corruptions) To generate line chart to visualise the accuracy results when general corruptions are applied <ul><li> Samples (General: Gaussian) </li><li> Samples (General: Poisson)</li> <li> Samples (General: Salt and Pepper)</li></ul> To generate sample images for the general corruptions Recommendation To provide recommendations for robustness (image corruptions) testing"},{"location":"stock_plugins/image_corruption/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/image_corruption/#data-preparation","title":"Data Preparation","text":"<ul> <li>Image dataset (Tutorial for Preparation)</li> <li>Annotated Ground Truth Dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/image_corruption/#additional-requirements","title":"Additional Requirements","text":"<ul> <li>ImageMagick (Details for installation can be found here)</li> </ul>"},{"location":"stock_plugins/image_corruption/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"<p>Note: These inputs are the same for all the algorithms in this plugin (Blur Corruptions, Digital Corruptions, Environmental Corruptions and General Corruptions)</p> Input Field Description Type Annotated ground truth path An uploaded dataset containing image file names and the corresponding ground truth label <code>string</code> Name of column containing image file name Key in the name of the column containing the file names in the annotated ground truth dataset <code>string</code> Seed for selection of data for display Some of the plugins selects a random sample data for display. The random seed for this selection can be changed, if desired. The default value we are using is 10. <code>int</code>"},{"location":"stock_plugins/image_corruption/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/image_corruption/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"annotated_ground_truth_path\",\n\"file_name_label\",\n\"set_seed\"\n],\n\"properties\": {\n\"annotated_ground_truth_path\": {\n\"title\": \"Annotated ground truth path\",\n\"description\": \"Select the dataset containing image file names and corresponding ground truth labels\",\n\"type\": \"string\",\n\"ui:widget\": \"selectDataset\"\n},\n\"file_name_label\": {\n\"title\": \"Name of column containing image file names\",\n\"description\": \"Key in the name of the column containing the file names in the annotated ground truth dataset\",\n\"type\": \"string\"\n},\n\"set_seed\": {\n\"title\": \"Seed for selection of data for display\",\n\"description\": \"Change to a specific seed for random selection the sample data for display if desired\",\n\"default\": 10,\n\"type\": \"integer\"\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"results\"\n],\n\"minProperties\": 1,\n\"properties\": {\n\"results\": {\n\"description\": \"Results from the unadverserial robustness algorithms\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"object\",\n\"required\": [\n\"corruption_group\",\n\"corruption_function\",\n\"accuracy\",\n\"display_info\"\n],\n\"properties\": {\n\"corruption_group\": {\n\"description\": \"Broad corruption group\",\n\"type\": \"string\"\n},\n\"corruption_function\": {\n\"description\": \"Name of corruption algorithm\",\n\"type\": \"string\"\n},\n\"accuracy\": {\n\"description\": \"Accuracies starting from no corruption to higher levels of severities\",\n\"items\": {\n\"type\": \"object\",\n\"minProperties\": 1,\n\"patternProperties\": {\n\"^severity\": {\n\"type\": \"number\"\n}\n}\n}\n},\n\"display_info\": {\n\"description\": \"Information for the display of sample images\",\n\"type\": \"object\",\n\"items\":{\n\"minProperties\": 6,\n\"patternProperties\": {\n\"^severity\": {\n\"type\": \"array\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/pdp/","title":"Partial Dependence Plot","text":"<p>(aiverify.stock.partial-dependence-plot) [source]</p>"},{"location":"stock_plugins/pdp/#description","title":"Description","text":"<p>This plugin explains how each feature and its feature value contribute to the predictions. The results are visualised as line graphs for each feature.</p>"},{"location":"stock_plugins/pdp/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Partial Dependence Plot A Partial Dependence Plot (PDP) explains how each feature and its feature value contribute to the predictions. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to Partial Dependence Plot PDP Line Graphs To generate and display PDP values in line graphs for each feature in each class output Recommendation To provide recommendations on explainability"},{"location":"stock_plugins/pdp/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/pdp/#data-preparation","title":"Data Preparation","text":"<ul> <li>Tabular dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/pdp/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/pdp/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"properties\": {\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\":\"Algorithm Plugin Output Arguments\",\n\"description\":\"A schema for algorithm plugin output arguments\",\n\"type\":\"object\",\n\"required\":[\n\"feature_names\",\n\"results\"\n],\n\"properties\":{\n\"feature_names\":{\n\"type\":\"array\",\n\"description\":\"Array of feature names\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"string\"\n}\n},\n\"output_classes\":{\n\"description\":\"Array of output classes\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":[\n\"string\",\n\"number\",\n\"integer\",\n\"boolean\"\n]\n}\n},\n\"results\":{\n\"description\":\"Matrix of feature values (# feature names)\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"description\":\"Matrix of PDP plot data (# output classes)\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"array\",\n\"description\":\"Array of PDP values for each feature value (# feature values)\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"object\",\n\"description\":\"Array of feature and PDP value\",\n\"required\":[\n\"feature_value\",\n\"pdp_value\"\n],\n\"properties\":{\n\"feature_value\":{\n\"type\":\"number\"\n},\n\"pdp_value\":{\n\"type\":\"number\"\n}\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/process_checklist/","title":"AI Verify Process Checklist","text":"<p>(aiverify.stock.process-checklist) [source]</p>"},{"location":"stock_plugins/process_checklist/#description","title":"Description","text":"<p>Process checklist for AI Verify framework</p>"},{"location":"stock_plugins/process_checklist/#plugin-content","title":"Plugin Content","text":"Name Description Overview Overview of AI Verify testing framework Principle Summary Header Summary header to be displayed before the principle summary Overall Summary Summary of all the processs checklists responses Area Descriptions List the framework areas and provide descriptions Area Header Header and description for each framework area <ul><li>Summary - Accountability</li><li>Summary - Data Governance</li><li>Summary - Explainability</li><li>Summary - Fairness</li><li>Summary - Human Agency &amp; Oversight</li><li>Summary - Inclusive Growth, Societal &amp; Environmental Well-Being</li><li>Summary - Reproducibility</li><li>Summary - Robustness</li><li>Summary - Safety</li><li>Summary - Security</li><li>Summary - Transparency</li></ul> Summary of the process checklist for each of the principles <ul><li>User Responses - Accountability</li><li>User Responses - Data Governance</li><li>User Responses - Explainability</li><li>User Responses - Fairness</li><li>User Responses - Human Agency &amp; Oversight</li><li>User Responses - Inclusive Growth, Societal &amp; Environmental Well-Being</li><li>User Responses - Reproducibility</li><li>User Responses - Robustness</li><li>User Responses - Safety</li><li>User Responses - Security</li><li>User Responses - Transparency</li></ul> List the user responses for the process checklists"},{"location":"stock_plugins/report/","title":"AI Verify Stock Reports","text":"<p>(aiverify.stock.reports) [source]</p>"},{"location":"stock_plugins/report/#description","title":"Description","text":"<p>Stock reports for AI Verify</p>"},{"location":"stock_plugins/report/#plugin-content","title":"Plugin Content","text":"<ul> <li>Templates</li> </ul> Name Description AI Verify Summary Report for Classification Model 0.9.0 Template AI Verify summary report for classification model <ul> <li>Widgets</li> </ul> Name Description AIV Introduction Introduction to AI Verify Main Cover Page Main cover page for the reports Section Cover Page For decorating the cover page of a section Global Explainability Introduction Explains what is global explainability Explainability Testing Introduction Explains what is the explainability testing Fairness Testing Introduction Explains what is the fairness testing Robustness Testing Introduction Explains what is the robustness testing Page Divider Custom divider for report Page Title 1 Standard page title 1 Page Title 2 Standard page title 2 Page Title 3 Standard page title 3 Report Summary Report summary Technical Tests Summary Status information on technical test results Use Case And Model Tested Describe use case and model tested"},{"location":"stock_plugins/robustness_toolbox/","title":"Robustness Toolbox","text":"<p>(aiverify.stock.robustness-toolbox) [source]</p>"},{"location":"stock_plugins/robustness_toolbox/#description","title":"Description","text":"<p>This plugin generates a perturbed dataset using boundary attack algorithm on the test dataset. </p> <p>Boundary Attack is an attack that starts by adding a large amount of noise to a data point intentionally to cause a model it misclassified by the model. This plugin uses Salt-and-pepper noise to create the large amount of noise. Then, it will reduce the amount of noise added while maintaining misclassification. This algorithm does not depend on the underlying model's architecture or parameters.</p> <p>This algorithm is developed for image dataset but can also be used to create noise on tabular dataset. However, it is to note that testing on tabular dataset may warrant caution when interpreting the results as this is not well-tested.</p>"},{"location":"stock_plugins/robustness_toolbox/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Robustness Toolbox This algorithm generates a perturbed dataset using boundary attack algorithm on the test dataset <ul> <li>Widgets</li> </ul> Name Description Description (Summary) To provide introduction, interpretation and recommendations for robustness testing Bar Chart (Accuracy) To generate and display a bar chart of the orignal and perturbed dataset with interpretation of the results Description (Technical) To provide introduction, bar chart, interpretation and recommendations for robustness testing with technical details"},{"location":"stock_plugins/robustness_toolbox/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/robustness_toolbox/#data-preparation","title":"Data Preparation","text":"<p>This plugin was mainly designed for image datasets, but can also be used on tabular datasets.</p> <p>For images:</p> <ul> <li>Image dataset (Tutorial for Preparation)</li> <li>Annotated Ground Truth Dataset (Tutorial for Preparation)</li> </ul> <p>For tabular:</p> <ul> <li>Tabular dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/robustness_toolbox/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Annotated ground truth path For image datasets: An uploaded dataset containing image file names and the corresponding ground truth label  For tabular datasets: Select the ground truth dataset <code>string</code> Name of column containing image file name For image datasets: Key in the name of the column containing the file names in the annotated ground truth dataset  For tabular datasets: Key in <code>NA</code> <code>string</code>"},{"location":"stock_plugins/robustness_toolbox/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/robustness_toolbox/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n],\n\"properties\": {\n\"annotated_ground_truth_path\": {\n\"title\": \"Annotated ground truth path\",\n\"description\": \"Annotated ground truth path\",\n\"type\": \"string\",\n\"ui:widget\": \"selectDataset\"\n},\n\"file_name_label\": {\n\"title\": \"Name of column containing image file names\",\n\"description\": \"Key in the name of the column containing the file names in the annotated ground truth dataset\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"object\",\n\"required\": [\"num_of_perturbed_samples\", \"org_performance\", \"perturbed_performance\", \"num_of_failed_perturbed_samples\"],\n\"properties\": {\n\"num_of_perturbed_samples\": {\n\"description\": \"Number of final perturbed samples\",\n\"type\": \"number\"\n},\n\"original\": {\n\"description\": \"Performance for Original Dataset\",\n\"type\": \"number\"\n},\n\"adversarial\": {\n\"description\": \"Performance for Perturbed Dataset \",\n\"type\": \"number\"\n},\n\"num_of_failed_perturbed_samples\": {\n\"description\": \"Number of samples that failed to generate perturbed samples\",\n\"type\": \"number\"\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/shap/","title":"SHAP Toolbox","text":"<p>(aiverify.stock.shap-toolbox) [source]</p>"},{"location":"stock_plugins/shap/#description","title":"Description","text":"<p>This plugin explains how your features affect your overall predictions by using Shapley Values.</p>"},{"location":"stock_plugins/shap/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description SHAP Toolbox SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to SHAP Understanding Bar Chart To guide your users on reading the generated bar chart Bar Chart (Summary) To generate bar chart, interpretation and recommendations for explainability testing Bar Chart (Technical) To display the average SHAP values using a bar chart Recommendations To provide a recommendation for explainability testing"},{"location":"stock_plugins/shap/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/shap/#data-preparation","title":"Data Preparation","text":"<ul> <li>Tabular dataset (Tutorial for Preparation)</li> </ul>"},{"location":"stock_plugins/shap/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Type of explainability Options: [global (default), local]. Global explainability explains overall dataset. Local explainability explains a random data point. <code>string</code> Path of the background data Background data path <code>string</code> Size of the background Background samples (eg. 25) <code>int</code> Size of the test dataset Data Samples (eg. 25) <code>int</code>"},{"location":"stock_plugins/shap/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/shap/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"explain_type\",\n\"background_path\",\n\"background_samples\",\n\"data_samples\"\n],\n\"properties\": {\n\"explain_type\": {\n\"title\": \"Type of Explainability\",\n\"description\": \"Options: [global (default), local]. Global explainability explains overall dataset. Local explinability explains a random data point.\",\n\"type\": \"string\",\n\"default\": \"global\",\n\"enum\": [\n\"global\",\n\"local\"\n]\n},\n\"background_path\": {\n\"title\": \"Path of the Background Path\",\n\"description\": \"Background data path\",\n\"type\": \"string\",\n\"ui:widget\": \"selectDataset\"\n},\n\"background_samples\": {\n\"title\": \"Size of the Background\",\n\"description\": \"Background Samples (e.g. 25)\",\n\"type\": \"number\"\n},\n\"data_samples\": {\n\"title\": \"Size of the Test Dataset\",\n\"description\": \"Data Samples (e.g. 25)\",\n\"type\": \"number\"\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_names\",\n\"results\"\n],\n\"properties\": {\n\"feature_names\": {\n\"type\": \"array\",\n\"description\": \"Array of feature names\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"string\"\n}\n},\n\"results\": {\n\"description\": \"Matrix of feature values (# feature names)\",\n\"type\": \"object\",\n\"required\": [\n\"num_local_classes\",\n\"local\",\n\"single_explainer_values\",\n\"single_shap_values\",\n\"global_shap_values\",\n\"global_samples\",\n\"num_global_classes\",\n\"global\"\n],\n\"properties\": {\n\"num_local_classes\": {\n\"description\": \"Number of local classes\",\n\"type\": \"number\"\n},\n\"local\": {\n\"description\": \"# of local classes\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"description\": \"class values\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n},\n\"single_explainer_values\": {\n\"description\": \"array of single explainer values\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n},\n\"single_shap_values\": {\n\"description\": \"array of single shap values\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"description\": \"class values\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n},\n\"global_shap_values\": {\n\"description\": \"global shap values\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"array\",\n\"description\": \"Matrix of SHAP values (# samples x # features)\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"description\": \"Array of SHAP values for each feature\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n},\n\"global_samples\": {\n\"description\": \"Matrix of feature values (# samples x # features)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"array\",\n\"description\": \"Array of sample values for each feature\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n},\n\"num_global_classes\": {\n\"description\": \"Number of global classes\",\n\"type\": \"number\"\n},\n\"global\": {\n\"description\": \"# of global classes\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"}]}